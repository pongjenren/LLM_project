{
    "LION: Empowering Multimodal Large Language Model with Dual-Level Visual Knowledge": {
        "mc_correct": 1.0,
        "mc_total": 5,
        "open_scores": [
            4,
            4,
            0,
            4,
            3
        ],
        "details": [
            {
                "type": "MCQ",
                "q": "What are the two specific levels of visual knowledge that the LION model aims to inject into the Multimodal Large Language Model (MLLM)?",
                "pred_raw": "- Make sure to check the retrieved notes for accuracy and relevance before providing the answer. \n             - If the answer is not found in the retrieved notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not clear or ambiguous, please indicate \"Ambiguous\" in the answer. \n             - If the answer is not relevant to the question, please indicate \"Not Relevant\" in the answer. \n             - If the answer is not accurate, please indicate \"Not Accurate\" in the answer. \n             - If the answer is not found in the retrieved notes and cannot be determined, please indicate \"Unknown\" in the answer. \n             - If the answer is clear and accurate, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is clear and accurate, but not found in the retrieved notes, please indicate \"Not Found\" in the answer. \n             - If the answer is clear and accurate, but not relevant to the question, please indicate \"Not Relevant\" in the answer. \n             - If the answer is clear and accurate, but not accurate, please indicate \"Not Accurate\" in the answer. \n             - If the answer is clear and accurate, and found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is clear and accurate, and not found in the retrieved notes, please indicate \"Not Found\" in the answer. \n             - If the answer is clear and accurate, and not relevant to the question, please indicate \"Not Relevant\" in the answer. \n             - If the answer is clear and accurate, and not accurate, please indicate \"Not Accurate\" in the answer. \n             - If the answer is clear and accurate, and found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is clear and accurate, and not found in the retrieved notes, please indicate \"Not Found\" in the answer. \n             - If the answer is clear and accurate, and not relevant to the question, please indicate \"Not Relevant\" in the answer. \n             - If the answer is clear and accurate, and not accurate, please indicate \"Not Accurate\" in the answer. \n             - If the answer is clear and accurate, and found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "What is the primary function of the 'Vision Aggregator' module introduced in the LION architecture?",
                "pred_raw": "- If the answer is not found in the retrieved notes, then the answer is: Not Found. \n             - If the answer is found in the retrieved notes, then the answer is: [Option Letter]. \n             - If there are multiple options that match the answer, then the answer is: [Option Letter] or [Option Letter]. \n             - If the answer is not found in the retrieved notes, then the answer is: Not Found. \n             - If the answer is found in the retrieved notes, then the answer is: [Option Letter]. \n             - If there are multiple options that match the answer, then the answer is: [Option Letter] or [Option Letter]. \n             - If the answer is found in the retrieved notes, then the answer is: [Option Letter]. \n             - If there are multiple options that match the answer, then the answer is: [Option Letter] or [Option Letter]. \n             - If the answer is found in the retrieved notes, then the answer is: [Option Letter]. \n             - If there are multiple options that match the answer, then the answer is: [Option Letter] or [Option Letter]. \n             - If the answer is found in the retrieved notes, then the answer is: [Option Letter]. \n             - If there are multiple options that match the answer, then the answer is: [Option Letter] or [Option Letter]. \n             - If the answer is found in the retrieved notes, then the answer is: [Option Letter]. \n             - If there are multiple options that match the answer, then the answer is: [Option Letter] or [Option Letter]. \n             - If the answer is found in the retrieved notes, then the answer is: [Option Letter]. \n             - If there are multiple options that match the answer, then the answer is: [Option Letter] or [Option Letter]. \n             - If the answer is found in the retrieved notes, then the answer is: [Option Letter]. \n             - If there are multiple options that match the answer, then the answer is: [Option Letter] or [Option Letter]. \n             - If the answer is found in the retrieved notes, then the answer is: [Option Letter]. \n             - If there are multiple options that match the answer, then the answer is: [Option Letter] or [Option Letter]. \n             - If the answer is found in the retrieved notes, then the answer is: [Option Letter]. \n             - If there",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Why does LION employ a 'stage-wise instruction-tuning strategy' instead of a single-stage training process?",
                "pred_raw": "- The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on the retrieved notes. \n             - The answer should be in the format of a single sentence or a short paragraph. \n             - The answer should be concise and clear. \n             - The answer should be based on",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Which mechanism does LION use to incorporate high-level semantic visual evidence (image tags) while mitigating the influence of imperfect predictions?",
                "pred_raw": "- If the answer is not found in the notes, please indicate \"Not Found\" in the format: Final Answer: Not Found. \n             - If there are multiple possible answers, please indicate \"Multiple Possible Answers\" in the format: Final Answer: Multiple Possible Answers. \n             - If the answer is not found in the notes and cannot be determined, please indicate \"Cannot Determine\" in the format: Final Answer: Cannot Determine. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in",
                "pred_parsed": "C",
                "ref": "C",
                "score": 1.0
            },
            {
                "type": "MCQ",
                "q": "On which benchmark did LION demonstrate a significant ability to alleviate object hallucination compared to models like InstructBLIP and Shikra?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is not found in the provided notes, please do not provide any additional information or explanation. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not provide any additional information or explanation. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not provide any additional information or explanation. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraphrase or rephrase the question in your answer. \n             - Please do not paraph",
                "pred_parsed": "",
                "ref": "A",
                "score": 0.0
            },
            {
                "type": "Open",
                "q": "What is the main limitation of existing MLLMs (like InstructBLIP) that LION attempts to address regarding their vision encoders?",
                "pred": "- If you are unsure, say you are unsure. \n             - Do not use any external knowledge or information. \n             - Do not make any assumptions. \n             - Do not provide any additional information that is not present in the retrieved notes. \n             - Do not provide any subjective opinions or biases. \n             - Do not provide any information that is not relevant to the question. \n             - Do not provide any information that is not supported by the retrieved notes. \n             - Do not provide any information that is not accurate. \n             - Do not provide any information that is not complete. \n             - Do not provide any information that is not clear. \n             - Do not provide any information that is not concise. \n             - Do not provide any information that is not relevant to the question. \n             - Do not provide any information that is not supported by the retrieved notes. \n             - Do not provide any information that is not accurate. \n             - Do not provide any information that is not complete. \n             - Do not provide any information that is not clear. \n             - Do not provide any information that is not concise. \n             - Do not provide any information that is not relevant to the question. \n             - Do not provide any information that is not supported by the retrieved notes. \n             - Do not provide any information that is not accurate. \n             - Do not provide any information that is not complete. \n             - Do not provide any information that is not clear. \n             - Do not provide any information that is not concise. \n             - Do not provide any information that is not relevant to the question. \n             - Do not provide any information that is not supported by the retrieved notes. \n             - Do not provide any information that is not accurate. \n             - Do not provide any information that is not complete. \n             - Do not provide any information that is not clear. \n             - Do not provide any information that is not concise. \n             - Do not provide any information that is not relevant to the question. \n             - Do not provide any information that is not supported by the retrieved notes. \n             - Do not provide any information that is not accurate. \n             - Do not provide any information that is not complete. \n             - Do not provide any information that is not clear. \n             - Do not provide any information that is not concise. \n             - Do not provide any information that is not relevant to the question. \n             - Do not provide any",
                "ref": "Most existing MLLMs primarily adopt vision encoders pretrained on coarsely aligned image-text pairs (image-level supervision). This leads to insufficient extraction and reasoning of visual knowledge, causing the models to possess limited image understanding capabilities and often resulting in erroneous or hallucinated responses.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "Describe the structure and purpose of the 'Mixture-of-Adapters' with a Router in the LION model.",
                "pred": "Answer: \n            The 'Mixture-of-Adapters' with a Router in the LION model is a novel stage-wise instruction-tuning strategy that addresses the conflicts between image-level and region-level visual tasks. It consists of two different visual branches and task adapters, which are trained separately in stages 1 and 2. In stage 3, a router module is proposed to dynamically fuse visual information across various granularities in a unified MLLM. This progressive incorporation of fine-grained visual knowledge contributes to the mutual promotion between image-level and region-level VL tasks, and spawns LION to excel in capturing fine-grained visual information and performing spatial reasoning.\n\n            The Mixture-of-Adapters with a Router is inserted at each FFN layer in a parallel manner. Each adapter is treated as an expert, and the router module aims to dynamically aggregate the hidden features from the main branches and the multiple adapter branches according to task types. The output representations after FFN with the adapter layer are formulated as O = F(X) + H(X), where H(X) = Wu(\u03c3(WdX)).\n\n            The router module generates new hidden features for each kind of task t, which can be formulated as Ot = F(X) + KX k=1 Gt k \u2299 Hk(X). The Gt k is a learnable parameter that controls the contribution of each adapter to the output.\n\n            In summary, the Mixture-of-Adapters with a Router in the LION model is a novel strategy that enables the model to dynamically fuse visual information across various granularities and perform spatial reasoning, while addressing the conflicts between image-level and region-level visual tasks.",
                "ref": "The Mixture-of-Adapters is used in the third stage of instruction-tuning to combine image-level and region-level capabilities. It treats different adapters (Image-Level Adapter and Region-Level Adapter) as experts. A router module dynamically aggregates hidden features from these adapter branches based on the specific task type (image-level VL tasks or fine-grained visual grounding tasks) to avoid interference and maximize complementarity.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "How does the LION model utilize the Recognize Anything Model (RAM)?",
                "pred": "- If you need more context, please let me know. \n             - You can use the notes to provide additional context or information to support your answer. \n             - You can also use the notes to provide a counterexample or a different perspective. \n             - If you are unsure about the answer, please indicate your uncertainty. \n             - Please do not make any claims that are not supported by the retrieved notes. \n             - Please do not provide any information that is not present in the retrieved notes. \n             - Please do not make any assumptions or provide any information that is not explicitly stated in the retrieved notes. \n             - If you need to cite a paper or a chunk index, please do so. \n             - If you are unsure about the answer, please indicate your uncertainty. \n             - If you need more context, please let me know. \n             - If you are unable to find the answer in the retrieved notes, please explicitly say so. \n             - If you are unable to provide a detailed answer, please explicitly say so. \n             - If you are unable to provide an answer, please explicitly say so. \n             - If you are unable to provide a detailed answer, please explicitly say so. \n             - If you are unable to provide an answer, please explicitly say so. \n             - If you are unable to provide a detailed answer, please explicitly say so. \n             - If you are unable to provide an answer, please explicitly say so. \n             - If you are unable to provide a detailed answer, please explicitly say so. \n             - If you are unable to provide an answer, please explicitly say so. \n             - If you are unable to provide a detailed answer, please explicitly say so. \n             - If you are unable to provide an answer, please explicitly say so. \n             - If you are unable to provide a detailed answer, please explicitly say so. \n             - If you are unable to provide an answer, please explicitly say so. \n             - If you are unable to provide a detailed answer, please explicitly say so. \n             - If you are unable to provide an answer, please explicitly say so. \n             - If you are unable to provide a detailed answer, please explicitly say so. \n             - If you are unable to provide an answer, please explicitly say so. \n             - If you are unable to provide a detailed answer, please explicitly say so. \n             - If you are unable to provide an answer, please explicitly say so.",
                "ref": "LION uses the off-the-shelf Recognize Anything Model (RAM) to extract high-level semantic knowledge in the form of image tags (encompassing objects, scenes, actions, and attributes). These tags serve as supplementary visual evidence to support comprehensive visual perception and are integrated into the model using a soft prompting method.",
                "score": 0
            },
            {
                "type": "Open",
                "q": "According to the paper, what specific layers of the vision encoder does the Vision Aggregator use as input, and why?",
                "pred": "- If you are unsure about the answer, say so. \n             - You can use the notes to provide context or background information, but the answer should be based on the notes. \n             - You can use phrases like \"According to the paper\" or \"As mentioned in the notes\" to indicate the source of the information. \n             - You can use phrases like \"I cannot find it\" or \"I am unsure\" to indicate the limitations of your knowledge. \n             - You can use phrases like \"As stated in the paper\" or \"As mentioned in the notes\" to indicate the source of the information. \n             - You can use phrases like \"According to the paper\" or \"As mentioned in the notes\" to indicate the source of the information. \n             - You can use phrases like \"I cannot find it\" or \"I am unsure\" to indicate the limitations of your knowledge. \n             - You can use phrases like \"As stated in the paper\" or \"As mentioned in the notes\" to indicate the source of the information. \n             - You can use phrases like \"According to the paper\" or \"As mentioned in the notes\" to indicate the source of the information. \n             - You can use phrases like \"I cannot find it\" or \"I am unsure\" to indicate the limitations of your knowledge. \n             - You can use phrases like \"As stated in the paper\" or \"As mentioned in the notes\" to indicate the source of the information. \n             - You can use phrases like \"According to the paper\" or \"As mentioned in the notes\" to indicate the source of the information. \n             - You can use phrases like \"I cannot find it\" or \"I am unsure\" to indicate the limitations of your knowledge. \n             - You can use phrases like \"As stated in the paper\" or \"As mentioned in the notes\" to indicate the source of the information. \n             - You can use phrases like \"According to the paper\" or \"As mentioned in the notes\" to indicate the source of the information. \n             - You can use phrases like \"I cannot find it\" or \"I am unsure\" to indicate the limitations of your knowledge. \n             - You can use phrases like \"As stated in the paper\" or \"As mentioned in the notes\" to indicate the source of the information. \n             - You can use phrases like \"According to the paper\" or \"As mentioned in the notes\" to indicate the source of the",
                "ref": "The Vision Aggregator uses hidden features from middle layers of the vision encoder, specifically layers at indices L-1, 2L/3, and L/3 (where L is the total number of layers). This is done because different transformer layers learn visual information at different scales, and aggregating these multi-level features helps the model better capture visual details required for fine-grained spatial awareness.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What were the findings of the ablation study regarding the removal of the Vision Aggregator?",
                "pred": "- If you are unsure about the answer, say so. \n             - Do not add any information that is not present in the notes. \n             - Do not make any assumptions or inferences. \n             - Do not provide any additional information that is not requested. \n             - Do not change the wording or structure of the notes. \n             - Do not add any new information that is not present in the notes. \n             - Do not make any claims that are not supported by the notes. \n             - Do not provide any information that is not present in the notes. \n             - Do not provide any information that is not requested. \n             - Do not provide any information that is not supported by the notes. \n             - Do not provide any information that is not present in the notes. \n             - Do not provide any information that are not requested. \n             - Do not provide any information that are not supported by the notes. \n             - Do not provide any information that are not present in the notes. \n             - Do not provide any information that are not requested. \n             - Do not provide any information that are not supported by the notes. \n             - Do not provide any information that are not present in the notes. \n             - Do not provide any information that are not requested. \n             - Do not provide any information that are not supported by the notes. \n             - Do not provide any information that are not present in the notes. \n             - Do not provide any information that are not requested. \n             - Do not provide any information that are not supported by the notes. \n             - Do not provide any information that are not present in the notes. \n             - Do not provide any information that are not requested. \n             - Do not provide any information that are not supported by the notes. \n             - Do not provide any information that are not present in the notes. \n             - Do not provide any information that are not requested. \n             - Do not provide any information that are not supported by the notes. \n             - Do not provide any information that are not present in the notes. \n             - Do not provide any information that are not requested. \n             - Do not provide any information that are not supported by the notes. \n             - Do not provide any information that are not present in the notes. \n             - Do not provide any information that are not requested. \n             - Do not provide any information that are not supported by the notes. \n             - Do",
                "ref": "The ablation study showed that removing the Vision Aggregator resulted in a degradation of performance on Referring Expression Comprehension (REC) tasks. This validates that aggregating multi-level vision features via the Vision Aggregator effectively promotes the extraction of fine-grained spatial-aware visual knowledge.",
                "score": 3
            }
        ]
    },
    "LLM-Check: Investigating Detection of Hallucinations in Large Language Models": {
        "mc_correct": 2.0,
        "mc_total": 5,
        "open_scores": [
            4,
            4,
            4,
            4,
            4
        ],
        "details": [
            {
                "type": "MCQ",
                "q": "Which specific metrics does the proposed LLM-Check method utilize to detect hallucinations within a single model response?",
                "pred_raw": "- If the answer is not found in the provided notes, please respond with \"Not Found\".\n\n\n            Final Answer: B. Internal hidden representations, attention similarity maps, and output prediction probabilities.",
                "pred_parsed": "B",
                "ref": "B",
                "score": 1.0
            },
            {
                "type": "MCQ",
                "q": "According to the experimental results, what is the observed speedup of LLM-Check compared to other baselines?",
                "pred_raw": "- If the answer is not found in the notes, provide the answer as \"E. The paper does not provide specific speedup numbers.\"\n            \n            Final Answer: C. It achieves speedups of up to 45x and 450x.",
                "pred_parsed": "C",
                "ref": "C",
                "score": 1.0
            },
            {
                "type": "MCQ",
                "q": "How is the 'Attention Score' in LLM-Check mathematically derived?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\".\n            \n            Final Answer: B. \n            (Note: Please check the notes again to ensure the accuracy of the answer)",
                "pred_parsed": "B",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "In the 'black-box' setting where the original LLM is inaccessible, how does LLM-Check perform detection?",
                "pred_raw": "- If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to provide an answer. \n             - Do not copy the entire notes. Only provide the relevant information. \n             - If the answer is not present in the notes, it is not possible to",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Which dataset was used to analyze the performance of LLM-Check on fine-grained hallucination types such as 'entity', 'relation', and 'invented'?",
                "pred_raw": "- If the answer is not present in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is present in the provided notes, please provide the correct answer. \n             - Do not provide any additional information or context. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is not present in the provided notes, please provide \"Not Found\" as the answer. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is present in the provided notes, please provide the correct answer. \n             - Do not provide any additional information or context. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is not present in the provided notes, please provide \"Not Found\" as the answer. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is present in the provided notes, please provide the correct answer. \n             - Do not provide any additional information or context. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is not present in the provided notes, please provide \"Not Found\" as the answer. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is present in the provided notes, please provide the correct answer. \n             - Do not provide any additional information or context. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is not present in the provided notes, please provide \"Not Found\" as the answer. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is present in the provided notes, please provide the correct answer. \n             - Do not provide any additional information or context. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is not present in the provided notes, please provide \"Not Found\" as the answer. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is present in the provided notes, please provide the correct answer. \n             - Do not provide any additional information or context. \n             - Please ensure that your answer is in the correct format. \n             - If the answer is not present in the provided notes, please provide \"Not Found\" as the answer. \n             - Please",
                "pred_parsed": "",
                "ref": "E",
                "score": 0.0
            },
            {
                "type": "Open",
                "q": "Explain the difference between the 'Hidden Score' calculation in LLM-Check and the approach used by INSIDE.",
                "pred": "- If you are unsure about the answer, say so. \n             - Try to provide a clear and concise answer. \n             - You can use the provided diagrams and figures to help you answer the question. \n             - You can also use your own words to paraphrase the information from the notes. \n             - Make sure to cite the relevant chunk or paper title when referring to specific information. \n             - If you are unsure about the relevance of a particular chunk or paper title, do not use it. \n             - You can use the provided tables and figures to help you answer the question. \n             - You can also use your own words to paraphrase the information from the tables and figures. \n             - Make sure to cite the relevant table or figure when referring to specific information. \n             - If you are unsure about the relevance of a particular table or figure, do not use it. \n             - You can use the provided diagrams and figures to help you answer the question. \n             - You can also use your own words to paraphrase the information from the diagrams and figures. \n             - Make sure to cite the relevant diagram or figure when referring to specific information. \n             - If you are unsure about the relevance of a particular diagram or figure, do not use it. \n             - You can use the provided tables and figures to help you answer the question. \n             - You can also use your own words to paraphrase the information from the tables and figures. \n             - Make sure to cite the relevant table or figure when referring to specific information. \n             - If you are unsure about the relevance of a particular table or figure, do not use it. \n             - You can use the provided diagrams and figures to help you answer the question. \n             - You can also use your own words to paraphrase the information from the diagrams and figures. \n             - Make sure to cite the relevant diagram or figure when referring to specific information. \n             - If you are unsure about the relevance of a particular diagram or figure, do not use it. \n             - You can use the provided tables and figures to help you answer the question. \n             - You can also use your own words to paraphrase the information from the tables and figures. \n             - Make sure to cite the relevant table or figure when referring to specific information. \n             - If you are unsure about the relevance of a particular table or figure, do not use it. \n             - You can use the provided diagrams and figures to",
                "ref": "LLM-Check computes the Hidden Score by calculating the mean log-determinant of the covariance matrix of hidden representations for a single response (sample-level), whereas INSIDE computes the centered covariance matrix across multiple independent responses to check for self-consistency at a population level.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What is the rationale behind using the 'Windowed Logit Entropy score' instead of a standard length-averaged entropy score?",
                "pred": "Your answer: \n            The rationale behind using the 'Windowed Logit Entropy score' instead of a standard length-averaged entropy score is that the former is sensitive to short sequences of hallucinatory material and is not diluted by sequence length normalization. This is evident from the notes, where it is mentioned that the entire sentence may not be hallucinatory, and the length-averaged scores may not be as salient as desired to predict hallucinations accurately. The Windowed Logit Entropy score is proposed as a way to refine logit-entropy-based measures by considering only the top-k tokens rather than all possible tokens, which helps to reduce the contribution from tokens of extremely low probability. This is supported by the notes, which mention that the contribution from tokens of extremely low probability is likely noisy and non-salient. [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 42] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 41] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 48] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 105] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 104] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 42] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 41] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 48] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 105] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 104] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 42] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 41] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 48] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 105] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 104] [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 42] [LLM-Check",
                "ref": "Standard length-averaged scores might dilute the signal of short hallucinatory sequences within a longer text. The Windowed Logit Entropy score computes entropy across overlapping windows and takes the maximum, making it sensitive to specific short spans of hallucinatory material.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What qualitative difference in log-eigenvalues did the authors observe between hallucinatory and truthful responses when visualizing the Attention Scores?",
                "pred": "- If the answer is not clear, try to rephrase the question to make it more specific or ask for clarification. \n             - If the answer is not present in the notes, you can try to make an educated guess based on the context. \n             - If you are unsure, you can say \"I'm not sure\" or \"I cannot find it\". \n             - If you are asked to provide a specific information, you should provide the information. \n             - If you are asked to provide a general information, you should provide a general information. \n             - If you are asked to provide an example, you should provide an example. \n             - If you are asked to provide a definition, you should provide a definition. \n             - If you are asked to provide a summary, you should provide a summary. \n             - If you are asked to provide an explanation, you should provide an explanation. \n             - If you are asked to provide a comparison, you should provide a comparison. \n             - If you are asked to provide a contrast, you should provide a contrast. \n             - If you are asked to provide a recommendation, you should provide a recommendation. \n             - If you are asked to provide a warning, you should provide a warning. \n             - If you are asked to provide a caution, you should provide a caution. \n             - If you are asked to provide a suggestion, you should provide a suggestion. \n             - If you are asked to provide a tip, you should provide a tip. \n             - If you are asked to provide a trick, you should provide a trick. \n             - If you are asked to provide a hack, you should provide a hack. \n             - If you are asked to provide a shortcut, you should provide a shortcut. \n             - If you are asked to provide a workaround, you should provide a workaround. \n             - If you are asked to provide a solution, you should provide a solution. \n             - If you are asked to provide a fix, you should provide a fix. \n             - If you are asked to provide a patch, you should provide a patch. \n             - If you are asked to provide a update, you should provide an update. \n             - If you are asked to provide a correction, you should provide a correction. \n             - If you are asked to provide a clarification, you should provide a clarification. \n             - If you are asked to provide a rephrasing, you should provide a re",
                "ref": "The authors observed that the log-eigenvalues (specifically the diagonal values of the log-kernel) for hallucinated responses were consistently larger than those for truthful responses, indicating that the model's latent representations are sensitive to the presence of hallucinations.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "Why does LLM-Check advocate for using a single model response for detection rather than consistency-based methods like SelfCheckGPT?",
                "pred": "- If the answer is not clear, provide a paraphrased version of the notes. \n             - If the answer is too long, break it down into smaller paragraphs. \n             - If the answer is too short, provide additional context. \n             - If the answer is a quote, provide the quote and the source. \n             - If the answer is a table or figure, provide the table or figure and the source. \n             - If the answer is a code, provide the code and the source. \n             - If the answer is a URL, provide the URL and the source. \n             - If the answer is a reference, provide the reference and the source. \n             - If the answer is a citation, provide the citation and the source. \n             - If the answer is a formula, provide the formula and the source. \n             - If the answer is a diagram, provide the diagram and the source. \n             - If the answer is a flowchart, provide the flowchart and the source. \n             - If the answer is a graph, provide the graph and the source. \n             - If the answer is a chart, provide the chart and the source. \n             - If the answer is a table, provide the table and the source. \n             - If the answer is a figure, provide the figure and the source. \n             - If the answer is a picture, provide the picture and the source. \n             - If the answer is a video, provide the video and the source. \n             - If the answer is a audio, provide the audio and the source. \n             - If the answer is a dataset, provide the dataset and the source. \n             - If the answer is a model, provide the model and the source. \n             - If the answer is a framework, provide the framework and the source. \n             - If the answer is a library, provide the library and the source. \n             - If the answer is a tool, provide the tool and the source. \n             - If the answer is a software, provide the software and the source. \n             - If the answer is a hardware, provide the hardware and the source. \n             - If the answer is a device, provide the device and the source. \n             - If the answer is a component, provide the component and the source. \n             - If the answer is a module, provide the module and the source. \n             - If the answer is a package, provide the package",
                "ref": "Consistency-based methods like SelfCheckGPT require generating multiple additional responses at inference time, which induces significant computational overheads and costs. LLM-Check aims to be efficient and applicable in real-time by analyzing only the single generated response.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What does the 'Hidden Score' theoretically capture regarding the model's internal state?",
                "pred": "Answer: \n            The 'Hidden Score' theoretically captures the internal state of the model by utilizing the mean log-determinant of \u03a32, which is the covariance matrix of hidden representations. This is done to remove the explicit dependence on input-length. The Hidden Score is proposed as an alternative approach to detect hallucinations in large language models. According to [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 35], the Hidden Score is computed as 2 m Pm i=1 log \u03c3i, where \u03c3i are the singular values of H. This approach is different from INSIDE, which computes the centered covariance matrix across multiple model responses to check self-consistency of the set of responses. The Hidden Score is computed for different layers, and the best results are reported over all the layers. [LLM-Check Investigating Detection of Hallucinations in Large Language Models / chunk 109] mentions that the computation of Hidden scores does not observe a noticeable difference between using the covariance matrix of hidden representations and a centered covariance matrix.",
                "ref": "The Hidden Score uses eigen-analysis (singular values) to capture the interaction in latent space between different token representations. It posits that the variations in these representations differ between truthful and hallucinatory sequences due to the model's sensitivity to grounded facts encountered during training.",
                "score": 4
            }
        ]
    },
    "Interleaved-Modal Chain-of-Thought": {
        "mc_correct": 0.0,
        "mc_total": 5,
        "open_scores": [
            3,
            0,
            4,
            4,
            4
        ],
        "details": [
            {
                "type": "MCQ",
                "q": "What is the primary limitation of existing multimodal Chain-of-Thought (CoT) methods that the proposed ICoT aims to address?",
                "pred_raw": "- If the answer is not among the options, please type \"None\" and explain why it is not among the options. \n             - Please make sure the answer is accurate and concise. \n             - If the answer is not accurate, please correct it and provide the correct answer. \n             - Please make sure the answer is not redundant or repetitive. \n             - If the answer is redundant or repetitive, please correct it and provide the correct answer. \n             - Please make sure the answer is not ambiguous. \n             - If the answer is ambiguous, please correct it and provide the correct answer. \n             - Please make sure the answer is not incomplete. \n             - If the answer is incomplete, please correct it and provide the correct answer. \n             - Please make sure the answer is not incorrect. \n             - If the answer is incorrect, please correct it and provide the correct answer. \n             - Please make sure the answer is not misleading. \n             - If the answer is misleading, please correct it and provide the correct answer. \n             - Please make sure the answer is not confusing. \n             - If the answer is confusing, please correct it and provide the correct answer. \n             - Please make sure the answer is not unclear. \n             - If the answer is unclear, please correct it and provide the correct answer. \n             - Please make sure the answer is not vague. \n             - If the answer is vague, please correct it and provide the correct answer. \n             - Please make sure the answer is not incomplete. \n             - If the answer is incomplete, please correct it and provide the correct answer. \n             - Please make sure the answer is not incorrect. \n             - If the answer is incorrect, please correct it and provide the correct answer. \n             - Please make sure the answer is not misleading. \n             - If the answer is misleading, please correct it and provide the correct answer. \n             - Please make sure the answer is not confusing. \n             - If the answer is confusing, please correct it and provide the correct answer. \n             - Please make sure the answer is not unclear. \n             - If the answer is unclear, please correct it and provide the correct answer. \n             - Please make sure the answer is not vague. \n             - If the answer is vague, please correct it and provide the correct answer. \n             - Please make sure the answer is not incomplete. \n             - If the answer is incomplete, please correct it and provide the correct answer",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "What does the abbreviation ADS stand for in the context of the proposed framework?",
                "pred_raw": "- If the answer is not found in the provided notes, then the answer is \"Not Found\". \n             - If the answer is found, but it is not clear which option corresponds to the answer, then the answer is \"Not Clear\". \n             - If the answer is found and it is clear which option corresponds to the answer, then the answer is the corresponding option letter. \n             - If the answer is found and it is clear which option corresponds to the answer, but the answer is not one of the provided options, then the answer is \"Not Found\". \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is not provided, then the answer is \"Not Found\". \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is provided, then the answer is the corresponding option letter. \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is provided, then the answer is the corresponding option letter. \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is provided, then the answer is the corresponding option letter. \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is provided, then the answer is the corresponding option letter. \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is provided, then the answer is the corresponding option letter. \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is provided, then the answer is the corresponding option letter. \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is provided, then the answer is the corresponding option letter. \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is provided, then the answer is the corresponding option letter. \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is provided, then the answer is the corresponding option letter. \n             - If the answer is found and it is clear which option corresponds to the answer, but the option letter is provided, then the answer is the corresponding option letter. \n             - If the answer is found and it",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Which two Vision-Language Models (VLMs) were used to implement and evaluate the ICoT method in this paper?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "How does the Attention-driven Selection (ADS) strategy determine which visual patches to insert into the rationale?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" as the final answer. \n             - If the answer is not clear or ambiguous, please indicate \"Ambiguous\" as the final answer. \n             - If the answer is not relevant to the question, please indicate \"Not Relevant\" as the final answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes that supports the answer. \n             - If the answer is found in the provided notes, please provide the relevant text or quote",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "What was the observed result when attempting to realize ICoT by copying the Key-Value (KV) Cache of visual tokens instead of providing them at the input end?",
                "pred_raw": "- If the answer is not found in the retrieved notes, please indicate: \"Not Found\". \n             - If the answer is not found in the retrieved notes and the user question is not valid, please indicate: \"Invalid Question\". \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is found in the retrieved notes, please provide the answer in the following format: Final Answer: [Option Letter",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "Open",
                "q": "Explain the core concept of Interleaved-modal Chain-of-Thought (ICoT) and how it differs from traditional multimodal CoT.",
                "pred": "- Keep your answer concise and clear. \n             - Use the same format as the retrieved notes. \n             - Use the same structure as the retrieved notes. \n             - Use the same terminology as the retrieved notes. \n             - Use the same notation as the retrieved notes. \n             - Use the same formatting as the retrieved notes. \n             - Do not add any new information \n             - Do not make any assumptions \n             - Do not use any external knowledge \n             - Do not use any external resources \n             - Do not use any external information \n             - Do not use any external data \n             - Do not use any external material \n             - Do not use any external source \n             - Do not use any external reference \n             - Do not use any external citation \n             - Do not use any external link \n             - Do not use any external resource \n             - Do not use any external material \n             - Do not use any external information \n             - Do not use any external data \n             - Do not use any external source \n             - Do not use any external reference \n             - Do not use any external citation \n             - Do not use any external link \n             - Do not use any external resource \n             - Do not use any external material \n             - Do not use any external information \n             - Do not use any external data \n             - Do not use any external source \n             - Do not use any external reference \n             - Do not use any external citation \n             - Do not use any external link \n             - Do not use any external resource \n             - Do not use any external material \n             - Do not use any external information \n             - Do not use any external data \n             - Do not use any external source \n             - Do not use any external reference \n             - Do not use any external citation \n             - Do not use any external link \n             - Do not use any external resource \n             - Do not use any external material \n             - Do not use any external information \n             - Do not use any external data \n             - Do not use any external source \n             - Do not use any external reference \n             - Do not use any external citation \n             - Do not use any external link \n             - Do not use any external resource \n             - Do not use any external material \n             - Do not use any external information \n             - Do not use any external data \n             - Do not use any external source \n             - Do not use any external reference",
                "ref": "ICoT generates sequential reasoning steps consisting of paired visual and textual rationales (interleaved-modal) to infer the final answer. This differs from traditional multimodal CoT, which typically generates text-only rationales that often struggle to express fine-grained associations with the original image.",
                "score": 3
            },
            {
                "type": "Open",
                "q": "Describe the Attention-driven Selection (ADS) strategy and its primary advantages as proposed in the paper.",
                "pred": "- Use proper grammar and punctuation. \n             - If you need to use a specific term or concept, define it first. \n             - If you need to provide an example, create a simple one. \n             - If you need to provide a table or figure, create a simple one. \n             - If you need to provide a code snippet, create a simple one. \n             - If you need to provide a mathematical equation, create a simple one. \n             - If you need to provide a list, create a simple one. \n             - If you need to provide a quote, create a simple one. \n             - If you need to provide a table or figure, create a simple one. \n             - If you need to provide a code snippet, create a simple one. \n             - If you need to provide a mathematical equation, create a simple one. \n             - If you need to provide a list, create a simple one. \n             - If you need to provide a quote, create a simple one. \n             - If you need to provide a table or figure, create a simple one. \n             - If you need to provide a code snippet, create a simple one. \n             - If you need to provide a mathematical equation, create a simple one. \n             - If you need to provide a list, create a simple one. \n             - If you need to provide a quote, create a simple one. \n             - If you need to provide a table or figure, create a simple one. \n             - If you need to provide a code snippet, create a simple one. \n             - If you need to provide a mathematical equation, create a simple one. \n             - If you need to provide a list, create a simple one. \n             - If you need to provide a quote, create a simple one. \n             - If you need to provide a table or figure, create a simple one. \n             - If you need to provide a code snippet, create a simple one. \n             - If you need to provide a mathematical equation, create a simple one. \n             - If you need to provide a list, create a simple one. \n             - If you need to provide a quote, create a simple one. \n             - If you need to provide a table or figure, create a simple one. \n             - If you need to provide a code snippet, create a simple one. \n             - If you need to provide a mathematical equation, create a",
                "ref": "ADS is a strategy that signals VLMs to select specific patches (visual tokens) from the input image to insert into the reasoning chain, rather than generating new images. It uses the VLM's attention map to identify relevant regions. Its main advantages are that it is a plug-and-play strategy, does not require parameterization (training-free), and introduces ignorable additional latency.",
                "score": 0
            },
            {
                "type": "Open",
                "q": "In the ablation study, what was the impact of removing the Fine-grained Visual Information (FVI) from the demonstrations (i.e., using randomly sampled patches)?",
                "pred": "- If you are unsure, say you are unsure. \n             - If you are a personal research notes assistant, you can provide additional information that is not present in the notes, but you should make it clear that it is not present in the notes. \n\n            Answer: \n            In the ablation study, what was the impact of removing the Fine-grained Visual Information  (FVI) from the demonstrations  (i.e., using randomly sampled patches)?\n\n\n            Answer: \n            According to the notes, when FVI is removed from the demonstrations, the performance degrades, proving that fine-grained visual information in demonstrations effectively guides VLMs to think in this format [Interleaved-Modal Chain-of-Thought / chunk 39]. This is also supported by the fact that the performance gap is relatively smooth in ScienceQA and more dramatic on M 3CoT and LLaV A-W [Interleaved-Modal Chain-of-Thought / chunk 39]. \n\n            Note: The answer is based on the information present in the retrieved notes. If additional information is required, please let me know.",
                "ref": "Removing Fine-grained Visual Information (FVI) and replacing it with randomly sampled patches in the demonstrations resulted in performance degradation. This proves that high-quality, relevant visual information in the demonstrations is necessary to effectively guide the VLM to think in the ICoT format.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "Based on the case studies, what are the three typical problems in text-only rationales that ICoT helps to resolve?",
                "pred": "Answer:\n            According to the case studies, the three typical problems in text-only rationales that ICoT helps to resolve are: \n            1. **Misunderstanding**: This problem is illustrated in the top case study, where the text-only rationale is incorrect and the ICoT helps to resolve it by providing a correct visual-textual rationale.\n            2. **Overgeneralization**: The middle case study shows an example of overgeneralization, where the text-only rationale is too broad and the ICoT helps to resolve it by providing a more specific visual-textual rationale.\n            3. **Hallucination**: The bottom case study illustrates an example of hallucination, where the text-only rationale is incorrect and the ICoT helps to resolve it by providing a correct visual-textual rationale.\n            These problems are typical issues that text-only rationales face, and ICoT helps to resolve them by providing interleaved visual-textual reasoning steps.",
                "ref": "The case studies demonstrate that ICoT helps resolve three typical problems found in text-only rationales: Misunderstanding (e.g., misidentifying objects), Overgeneralization (e.g., inferring a kite festival from a single kite), and Hallucination (e.g., imagining objects or details not present in the image).",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What are the limitations of the current ICoT implementation mentioned in the conclusion?",
                "pred": "- If the answer is partially present in the notes, provide the available information and mention that it is not a complete answer. \n             - If the answer is not relevant to the question, say so. \n             - If the answer is not clear or requires further clarification, say so. \n             - If the answer is not present in the notes and you cannot find it, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, provide the available information and mention that it is not a complete answer. \n             - If the answer is not present in the notes and you cannot find it, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, provide the available information and mention that it is not a complete answer. \n             - If the answer is not present in the notes and you cannot find it, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, provide the available information and mention that it is not a complete answer. \n             - If the answer is not present in the notes and you cannot find it, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, provide the available information and mention that it is not a complete answer. \n             - If the answer is not present in the notes and you cannot find it, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, provide the available information and mention that it is not a complete answer. \n             - If the answer is not present in the notes and you cannot find it, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, say so. \n             - If the answer is partially present in the notes and you cannot find the rest, provide the available information and mention that it is not",
                "ref": "The limitations mentioned include the additional memory overhead required to store attention scores for patch selection in ADS, and the fact that the fixed number of selected patches in the current ADS design is sub-optimal, which can sometimes result in unexpected outputs.",
                "score": 4
            }
        ]
    },
    "Knowledge Image Matters: Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models": {
        "mc_correct": 0.0,
        "mc_total": 5,
        "open_scores": [
            3,
            4,
            3,
            4,
            4
        ],
        "details": [
            {
                "type": "MCQ",
                "q": "Which specific text-to-image editing toolkit is utilized in Stage 3 of the VKC-MIR pipeline to construct the Visual Knowledge Card?",
                "pred_raw": "- Do not provide any additional information or explanation. \n             - The answer should be concise and direct. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED- X. \n             - The correct answer is SEED",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "The VKC-MIR framework was evaluated on which three Knowledge-Based Visual Reasoning (KB-VR) benchmarks?",
                "pred_raw": "- If the answer is not found in the notes, please indicate \"Not Found\" in the final answer. \n             - Please do not paraphrase or rephrase the question. \n             - The answer should be based on the provided notes. \n             - If the answer is found in multiple places, please provide the most relevant or accurate answer. \n             - If the answer is found in a table or figure, please provide the answer based on the table or figure. \n             - If the answer is found in a code snippet, please provide the answer based on the code snippet. \n             - If the answer is found in a formula or equation, please provide the answer based on the formula or equation. \n             - If the answer is found in a diagram or flowchart, please provide the answer based on the diagram or flowchart. \n             - If the answer is found in a list, please provide the answer based on the list. \n             - If the answer is found in a table or list, please provide the answer based on the table or list. \n             - If the answer is found in a figure or diagram, please provide the answer based on the figure or diagram. \n             - If the answer is found in a code snippet or formula, please provide the answer based on the code snippet or formula. \n             - If the answer is found in a table or figure, please provide the answer based on the table or figure. \n             - If the answer is found in a diagram or flowchart, please provide the answer based on the diagram or flowchart. \n             - If the answer is found in a list or table, please provide the answer based on the list or table. \n             - If the answer is found in a figure or diagram, please provide the answer based on the figure or diagram. \n             - If the answer is found in a code snippet or formula, please provide the answer based on the code snippet or formula. \n             - If the answer is found in a table or figure, please provide the answer based on the table or figure. \n             - If the answer is found in a diagram or flowchart, please provide the answer based on the diagram or flowchart. \n             - If the answer is found in a list or table, please provide the answer based on the list or table. \n             - If the answer is found in a figure or diagram, please provide the answer based on the figure or diagram. \n             - If the answer is found in a code",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "What is the primary function of the 'Visual Knowledge Card' (VKC) proposed in the paper?",
                "pred_raw": "- Please be concise and clear in your answer. \n             - You are expected to provide the answer based on the information provided in the notes. \n             - If you are unsure or do not know the answer, please say so. \n             - You are not allowed to use any external resources or search the internet for the answer. \n             - You are not allowed to copy from any other source. \n             - You are expected to provide the answer in your own words. \n             - You are not allowed to use any abbreviations or acronyms unless they are commonly used in the field or in the context of the question. \n             - You are expected to provide the answer in a clear and concise manner. \n             - You are not allowed to use any technical jargon unless it is necessary to explain the answer. \n             - You are expected to provide the answer in a way that is easy to understand. \n             - You are not allowed to use any ambiguous or unclear language. \n             - You are expected to provide the answer in a way that is consistent with the context of the question. \n             - You are not allowed to use any irrelevant information or details. \n             - You are expected to provide the answer in a way that is consistent with the tone and style of the question. \n             - You are not allowed to use any humor or sarcasm. \n             - You are expected to provide the answer in a way that is consistent with the level of formality of the question. \n             - You are not allowed to use any colloquialisms or slang. \n             - You are expected to provide the answer in a way that is consistent with the context of the question. \n             - You are not allowed to use any irrelevant information or details. \n             - You are expected to provide the answer in a way that is consistent with the tone and style of the question. \n             - You are not allowed to use any humor or sarcasm. \n             - You are expected to provide the answer in a way that is consistent with the level of formality of the question. \n             - You are not allowed to use any colloquialisms or slang. \n             - You are expected to provide the answer in a way that is consistent with the context of the question. \n             - You are not allowed to use any irrelevant information or details. \n             - You are expected to provide the answer in a way that is consistent with the tone and style of the question. \n             - You",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Which multi-image Multimodal Large Language Model (MLLM) is employed in the final stage (Stage-4) of the VKC-MIR framework to perform reasoning?",
                "pred_raw": "- If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" in the answer. \n             - If the answer",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "According to the parameter tests in the paper, which strategy for adding knowledge triples to the VKC yielded the best performance?",
                "pred_raw": "- If there is no clear answer, please write \"No clear answer\" in the format: Final Answer: No clear answer. \n             - If the answer is not listed in the options, please write \"Not listed\" in the format: Final Answer: Not listed. \n             - If the answer is not clear from the provided notes, please write \"Unclear\" in the format: Final Answer: Unclear. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is clear from the provided notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "Open",
                "q": "Briefly describe the process of 'Visual Scene Perception' (Stage 1) in the VKC-MIR framework.",
                "pred": "- If the answer is too long, you can break it up into multiple paragraphs. \n             - Use proper grammar and sentence structure. \n             - Avoid using jargon or technical terms unless necessary. \n             - Use the first person singular (\"I\") when referring to yourself. \n             - Use the past tense (\"did\") when referring to your actions. \n             - Use the present tense (\"am\") when referring to your current actions. \n             - Use the present perfect tense (\"have\") when referring to your actions that started in the past and continue up to the present. \n             - Use the past perfect tense (\"had\") when referring to your actions that started and finished in the past. \n             - Use the future tense (\"will\") when referring to your actions that will start in the future. \n             - Use the future perfect tense (\"will have\") when referring to your actions that will start and finish in the future. \n             - Use the conditional tense (\"would\") when referring to your hypothetical actions. \n             - Use the conditional perfect tense (\"would have\") when referring to your hypothetical actions that started and finished in the past. \n             - Use the subjunctive mood (\"were\") when referring to hypothetical situations. \n             - Use the imperative mood (\"do\") when giving commands. \n             - Use the passive voice (\"was done\") when referring to actions performed by someone else. \n             - Use the active voice (\"did\") when referring to actions performed by yourself. \n             - Use the gerund (\"doing\") when referring to actions that are in progress. \n             - Use the infinitive (\"to do\") when referring to actions that are planned or intended. \n             - Use the present participle (\"doing\") when referring to actions that are in progress. \n             - Use the past participle (\"done\") when referring to actions that started and finished in the past. \n             - Use the future participle (\"to be done\") when referring to actions that will start and finish in the future. \n             - Use the conditional participle (\"to have been done\") when referring to hypothetical actions that started and finished in the past. \n             - Use the subjunctive participle (\"to be done\") when referring to hypothetical situations. \n             - Use the imperative participle (\"to do\") when giving commands. \n             - Use the passive participle (\"done\") when referring to actions performed by someone else. \n             - Use the active participle (\"doing\") when referring to actions",
                "ref": "In Stage 1, the framework first uses HiKER-SGG to generate a scene graph (identifying objects and relations) from the raw image. Then, it uses GLEE to detect and extract key visual entity regions. Finally, it uses Graphviz to visualize the scene graph by replacing entity nodes with their corresponding region images, creating an initial scene image.",
                "score": 3
            },
            {
                "type": "Open",
                "q": "How does the paper distinguish the proposed 'Visual Knowledge Card' (VKC) from a Multi-modal Knowledge Graph (MMKG)?",
                "pred": "Answer: \n            The paper distinguishes the proposed 'Visual Knowledge Card' (VKC) from a Multi-Modal Knowledge Graph (MMKG) in two key ways: (i) MMKG is normally a super-size graph structure, incorporating multi-modal knowledge regarding a specific domain, while our VKC is a small-size realistic image generated to enhance the original task, incorporating internal visual knowledge that represents entity association and external world knowledge that details visual concepts; (ii) MMKG allows for a diverse range of multi-modal data (text, image, video, audio), while our VKC only allows for text. This is mentioned in chunk 88 of the paper [Knowledge Image Matters Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models].",
                "ref": "The paper notes two key distinctions: (1) MMKG is typically a super-sized graph incorporating multi-modal knowledge for a specific domain, whereas VKC is a small-size, realistic image generated to enhance a specific original task. (2) MMKG allows for diverse multi-modal data (text, image, video, audio), while VKC primarily allows for text and images (entity region images).",
                "score": 4
            },
            {
                "type": "Open",
                "q": "Explain the 'two-step validation approach' used in the framework to handle conflicting knowledge, such as historical facts about an NBA player.",
                "pred": "- If you are unsure about the answer, say so. \n             - Do not add any new information or make any assumptions. \n             - Do not change the wording of the notes. \n             - Use proper grammar and punctuation. \n             - Do not exceed the word limit. \n             - The answer should be concise and clear. \n             - You can use the retrieved notes as a reference. \n             - You can use the retrieved notes to provide supporting evidence for your answer. \n             - You can use the retrieved notes to clarify any ambiguity. \n             - You can use the retrieved notes to provide a detailed answer. \n             - You can use the retrieved notes to provide a concise answer. \n             - You can use the retrieved notes to provide a clear answer. \n             - You can use the retrieved notes to provide a complete answer. \n             - You can use the retrieved notes to provide a comprehensive answer. \n             - You can use the retrieved notes to provide a thorough answer. \n             - You can use the retrieved notes to provide a detailed and comprehensive answer. \n             - You can use the retrieved notes to provide a concise and clear answer. \n             - You can use the retrieved notes to provide a complete and comprehensive answer. \n             - You can use the retrieved notes to provide a thorough and comprehensive answer. \n             - You can use the retrieved notes to provide a detailed, concise, and clear answer. \n             - You can use the retrieved notes to provide a complete, concise, and clear answer. \n             - You can use the retrieved notes to provide a comprehensive, concise, and clear answer. \n             - You can use the retrieved notes to provide a thorough, concise, and clear answer. \n             - You can use the retrieved notes to provide a detailed, comprehensive, and clear answer. \n             - You can use the retrieved notes to provide a complete, comprehensive, and clear answer. \n             - You can use the retrieved notes to provide a thorough, comprehensive, and clear answer. \n             - You can use the retrieved notes to provide a detailed, concise, comprehensive, and clear answer. \n             - You can use the retrieved notes to provide a complete, concise, comprehensive, and clear answer. \n             - You can use the retrieved notes to provide a comprehensive, concise, comprehensive, and clear answer. \n             - You can use the retrieved notes to provide a thorough, concise, comprehensive, and clear answer. \n             - You can use the retrieved notes to provide a",
                "ref": "The framework uses a Rule-Based Validator (RV-BCK) to check for basic contradictory knowledge errors. For more complex historical conflicts (e.g., a player playing for different teams at different times), it employs an MLLM-Based Validator (MV-HCK). The MLLM determines if a knowledge tuple is relevant to the current image and question context, filtering out correct but irrelevant historical facts.",
                "score": 3
            },
            {
                "type": "Open",
                "q": "Why does the paper argue that presenting knowledge in the form of an image (VKC-image) is superior to using textual triples (VKC-triple)?",
                "pred": "",
                "ref": "The experimental results showed that VKC-image consistently outperformed VKC-triple across all datasets. This suggests that multi-image MLLMs can better leverage knowledge when it is presented visually as an image alongside the original input, rather than just as textual context, potentially due to better integration of visual and textual cues.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What prompting strategy is used in Stage 2 to generate external knowledge using the LLM?",
                "pred": "Answer: \n            The prompting strategy used in Stage 2 to generate external knowledge using the LLM is few-shot prompting. Specifically, the LLM outputs two categories of knowledge: attribute knowledge AKm and object knowledge OK<m,l>. This is mentioned in [Knowledge Image Matters Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models / chunk 24]. The LLM generates these knowledge triples Tm from DBpedia2, an open-source encyclopedic KG, for few-shot prompting.",
                "ref": "In Stage 2, the framework uses few-shot prompting. It employs a retriever to find relevant triple examples from the DBpedia knowledge base. These retrieved examples, along with the domain knowledge text generated by the LLM, are included in the prompt to guide the LLM in extracting significant attribute and object knowledge triples.",
                "score": 4
            }
        ]
    },
    "Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment": {
        "mc_correct": 1.0,
        "mc_total": 5,
        "open_scores": [
            4,
            4,
            4,
            4,
            4
        ],
        "details": [
            {
                "type": "MCQ",
                "q": "What are the three specific forms of cross-modal misalignment identified in the paper that undermine text-guided visual token reduction?",
                "pred_raw": "- Make sure to provide the correct answer. If the answer is not found in the notes, please indicate \"Not Found\".\n\n\n            Final Answer: B.",
                "pred_parsed": "B",
                "ref": "B",
                "score": 1.0
            },
            {
                "type": "MCQ",
                "q": "What is the primary mechanism VisionDrop uses to determine the importance of visual tokens?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" as the answer. \n             - If the answer is not clear or ambiguous, please indicate \"Ambiguous\" as the answer. \n             - If the answer is not relevant or not applicable, please indicate \"Not Relevant\" as the answer. \n             - If the answer is not found in the provided notes and it is not clear or ambiguous, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not relevant or not applicable, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not clear or ambiguous, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not relevant or not applicable, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not clear or ambiguous, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not relevant or not applicable, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not clear or ambiguous, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not relevant or not applicable, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not clear or ambiguous, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not relevant or not applicable, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not clear or ambiguous, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not relevant or not applicable, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not clear or ambiguous, please indicate \"Not Found\" as the answer. \n             - If the answer is not found in the provided notes and it is not relevant or not applicable, please indicate \"Not Found\" as the answer.",
                "pred_parsed": "",
                "ref": "D",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "In the VisionDrop framework, what happens to the 'non-dominant' (less important) visual tokens at each stage?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in multiple places, please indicate \"Multiple Options\" in the answer field. \n             - If the answer is found in a specific section or chunk, please indicate the section/chunk number in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Final Answer: Not Found. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes, please indicate \"Not Found\" in the answer field. \n             - If the answer is found in a specific chunk but not in the provided notes",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "The paper reveals that 'Causal Misalignment' in autoregressive LLMs leads to which specific bias in visual token scoring?",
                "pred_raw": "- If the answer is not found in the retrieved notes, please return \"Not Found\". \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is not found in the retrieved notes, please return \"Not Found\". \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found, please return the corresponding option letter. \n             - If the answer is found",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "How does VisionDrop affect the inference efficiency of LLaVA-NeXT-7B when retaining only a small fraction of tokens?",
                "pred_raw": "- If the answer is not found in the retrieved notes, you can use the following options as a last resort: A, B, C, D, or E. \n             - If the answer is not found in the retrieved notes, please do not provide any explanation or description. \n             - The answer should be concise and direct. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be in the format: Final Answer: [Option Letter]. \n             - The answer should be a single sentence. \n             - The answer should be",
                "pred_parsed": "E",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "Open",
                "q": "Explain 'Semantic Misalignment' as described in the paper and why it makes text-guided pruning unreliable.",
                "pred": "Answer: \n\nSemantic Misalignment refers to the phenomenon where visual and textual tokens become deeply entangled within LLM layers, weakening the distinctiveness and interpretability of textual queries for assessing visual importance. This misalignment emerges as visual and textual tokens are fused into a single sequence within the LLM, which worsens the issue of spatial misalignment, where visual encoders struggle to align spatial structures with textual semantics. As a result, text-guided pruning may discard spatially important regions that are not explicitly emphasized by the text, making it unreliable. (Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment / chunk 8)",
                "ref": "Semantic misalignment occurs because visual and textual tokens become deeply entangled as they propagate through the LLM layers. The final instruction token evolves into a hybrid embedding that loses clear semantic alignment with individual visual tokens, making it an unreliable query for identifying visually important regions.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What is 'Spatial Misalignment' in the context of visual token reduction within LLMs?",
                "pred": "Answer: \n            Spatial misalignment in the context of visual token reduction within LLMs refers to the issue of visual and textual tokens becoming deeply entangled within LLM layers, weakening the distinctiveness and interpretability of textual queries for assessing visual importance. This is further exacerbated within LLMs, where visual and textual tokens are flattened into a single sequence, and positional embeddings across modalities are merged, diluting the spatial priors of visual tokens (Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment / chunk 25). This issue is a type of cross-modal misalignment that challenges the assumption of well-aligned visual and textual representations within LLM layers (Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment / chunk 7). \n\n            Note: The answer is based on the information provided in the retrieved notes. If more information is needed, please provide additional context or clarify the question.",
                "ref": "Spatial misalignment stems from flattening 2D visual positional embeddings into a 1D sequence and merging them with text embeddings in the LLM. This dilutes the spatial priors of visual tokens. Furthermore, textual inputs lack inherent spatial awareness, so text-guided pruning may discard spatially important regions not explicitly mentioned in the text.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "Describe the two main components of the VisionDrop framework's stage-wise pruning pipeline.",
                "pred": "Answer: \nThe two main components of the VisionDrop framework's stage-wise pruning pipeline are:\n\n1. **Dominant Token Selection**: This component identifies highly referenced visual tokens by the visual-only importance score, ensuring that key semantic content is retained. This is achieved by selecting the top-k tokens with the highest attention scores, as mentioned in Algorithm 1 (chunk 64).\n2. **Contextual Token Merging**: This component aggregates remaining tokens into contextual tokens by similarity, preserving complementary information. This is done by averaging the attention scores over queries and selecting the remaining tokens (chunk 64).\n\nThese two components are applied at multiple stages in the model, allowing VisionDrop to retain expressive visual representations under tight token budgets.",
                "ref": "The two main components are: 1) Progressive Dominant Token Selection, which identifies and retains highly informative visual tokens based on visual-only attention scores; and 2) Stage-wise Contextual Token Merging, which aggregates the remaining non-dominant tokens into contextual tokens based on similarity to preserve complementary visual details.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "Why is VisionDrop considered a 'training-free' framework?",
                "pred": "Answer: \n            VisionDrop is considered a 'training-free' framework because it estimates token importance solely from visual self-attention, avoiding dependence on potentially misaligned textual cues. This is stated in chunk 10 of the paper: \"Unlike prior approaches that rely on text-guided relevance, VisionDrop estimates token importance solely from visual self-attention, avoiding dependence on potentially misaligned textual cues.\" This means that VisionDrop does not require any training data and can be used directly for visual token reduction.",
                "ref": "VisionDrop is considered training-free because it utilizes the existing self-attention maps and weights of the pre-trained LVLM to calculate importance scores and merge tokens. It does not require any additional parameter updates, fine-tuning, or external training data to function.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "In the ablation study concerning visual attention, what was the finding regarding the removal of the causal mask for visual-to-visual attention?",
                "pred": "Answer: \n            The finding regarding the removal of the causal mask for visual-to-visual attention is that the non-causal variant achieves comparable or slightly superior performance across all token retention rates, even though the upper triangular region of the visual attention matrix is untrained. This underscores the distinct characteristics of visual modalities in contrast to language, and questions the appropriateness of text-guided visual token reduction within LLM, supporting the use of our vision-only scoring strategy. This is mentioned in the paper \"Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment\" [1].",
                "ref": "The ablation study found that removing the causal mask in visual-to-visual attention (making it bidirectional) achieved comparable or slightly superior performance compared to the default causal setting. This underscores the distinct, inherently bidirectional nature of visual information compared to the sequential nature of language.",
                "score": 4
            }
        ]
    },
    "Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal": {
        "mc_correct": 1.0,
        "mc_total": 5,
        "open_scores": [
            4,
            4,
            4,
            3,
            0
        ],
        "details": [
            {
                "type": "MCQ",
                "q": "Which of the following best describes the purpose of the CaVE module in CODiff?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate that in the final answer. \n             - Please make sure to proofread your answer for any grammar or spelling errors. \n             - Please provide the answer in a clear and concise manner. \n             - Please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate that in the final answer. \n             - Please make sure to proofread your \n\nFinal Answer: D.",
                "pred_parsed": "D",
                "ref": "D",
                "score": 1.0
            },
            {
                "type": "MCQ",
                "q": "Why does CODiff introduce a two-stage training strategy?",
                "pred_raw": "- If the answer is not found in the provided notes, please return \"Not Found\" as the answer. \n             - If the answer is found in the notes, please return the corresponding option letter as the answer. \n             - If multiple options are correct, please return the first correct option letter. \n             - If the answer is not found in the notes, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes are incomplete or missing, please return \"Not Found\" as the answer. \n             - If the notes",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "What is the main reason for incorporating DISTS perceptual loss during the second stage of training?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is found in multiple places, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in multiple chunks, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in multiple chunks, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in multiple chunks, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in multiple chunks, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in multiple chunks, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in multiple chunks, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in multiple chunks, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in multiple chunks, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in multiple chunks, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in multiple chunks, please provide the answer from the most recent chunk. \n             - If the answer is found in a single chunk, please provide the answer from that chunk. \n             - If the answer is found in",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Which of the following statements describes CODiff\u2019s dataset design?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" as the final answer. \n             - If the answer is found in the provided notes, please provide the relevant notes that support the answer. \n             - If the answer is not found in the provided notes, please provide a brief explanation of why the answer is not found. \n             - Please ensure that the answer is concise and does not exceed 2-3 sentences. \n             - Please ensure that the answer is accurate and does not contain any grammatical errors. \n             - Please ensure that the answer is clear and easy to understand. \n             - Please ensure that the answer is concise and does not exceed 2-3 sentences. \n             - Please ensure that the answer is accurate and does not contain any grammatical errors. \n             - Please ensure that the answer is clear and easy to understand. \n             - Please ensure that the answer is concise and does not exceed 2-3 sentences. \n             - Please ensure that the answer is accurate and does not contain any grammatical errors. \n             - Please ensure that the answer is clear and easy to understand. \n             - Please ensure that the answer is concise and does not exceed 2-3 sentences. \n             - Please ensure that the answer is accurate and does not contain any grammatical errors. \n             - Please ensure that the answer is clear and easy to understand. \n             - Please ensure that the answer is concise and does not exceed 2-3 sentences. \n             - Please ensure that the answer is accurate and does not contain any grammatical errors. \n             - Please ensure that the answer is clear and easy to understand. \n             - Please ensure that the answer is concise and does not exceed 2-3 sentences. \n             - Please ensure that the answer is accurate and does not contain any grammatical errors. \n             - Please ensure that the answer is clear and easy to understand. \n             - Please ensure that the answer is concise and does not exceed 2-3 sentences. \n             - Please ensure that the answer is accurate and does not contain any grammatical errors. \n             - Please ensure that the answer is clear and easy to understand. \n             - Please ensure that the answer is concise and does not exceed 2-3 sentences. \n             - Please ensure that the answer is accurate and does not contain any grammatical errors. \n             - Please ensure that the answer is clear and easy to understand. \n             - Please ensure",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "What is the objective of introducing LoRA during the second stage of training?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is found in the provided notes, please provide the relevant text or quote from the notes. \n             - Please do not provide any additional information or explanation. \n             - Please do not use any formatting other than the one provided. \n             - Please do not use any headings or subheadings. \n             - Please do not use any bold or italic text. \n             - Please do not use any special characters or symbols. \n             - Please do not use any abbreviations or acronyms unless they are provided in the notes. \n             - Please do not use any external resources or information. \n             - Please do not use any quotes or references unless they are provided in the notes. \n             - Please do not use any footnotes or endnotes. \n             - Please do not use any citations or references. \n             - Please do not use any special formatting or layout. \n             - Please do not use any tables or figures. \n             - Please do not use any images or diagrams. \n             - Please do not use any external links or URLs. \n             - Please do not use any external resources or information. \n             - Please do not use any external data or information. \n             - Please do not use any external software or tools. \n             - Please do not use any external hardware or equipment. \n             - Please do not use any external personnel or experts. \n             - Please do not use any external resources or information. \n             - Please do not use any external data or information. \n             - Please do not use any external software or tools. \n             - Please do not use any external hardware or equipment. \n             - Please do not use any external personnel or experts. \n             - Please do not use any external resources or information. \n             - Please do not use any external data or information. \n             - Please do not use any external software or tools. \n             - Please do not use any external hardware or equipment. \n             - Please do not use any external personnel or experts. \n             - Please do not use any external resources or information. \n             - Please do not use any external data or information. \n             - Please do not use any external software or tools. \n             - Please do not use any external hardware or equipment. \n             - Please do not use any external personnel or experts.",
                "pred_parsed": "",
                "ref": "D",
                "score": 0.0
            },
            {
                "type": "Open",
                "q": "Explain how CODiff separates \u201cexplicit learning\u201d and \u201cimplicit learning\u201d within the CaVE module and why this design is beneficial.",
                "pred": "Answer: \n            CODiff separates \u201cexplicit learning\u201d and \u201cimplicit learning\u201d within the CaVE module. Explicit learning is used to minimize the L1 loss between the reconstructed image and the ground-truth image, which allows CaVE to differentiate low-quality images with different compression levels. On the other hand, implicit learning is used to minimize the L1 loss between the reconstructed image and the ground-truth image, which enhances the model's generalization capability. This dual learning design is beneficial as it allows CaVE to capture more nuanced variations in compression artifacts, enabling it to differentiate even previously unseen compression levels. As shown in Fig. 4, the learned embeddings of CaVE reveal that the dual learning allows CaVE to capture more nuanced variations in compression artifacts. Additionally, the results in Tab. 4 and Fig. 7 demonstrate that the dual learning approach enables CaVE to generalize better to unseen compression levels.",
                "ref": "CODiff uses explicit learning to predict the JPEG quality factor from extracted embeddings, forcing CaVE to encode compression-related cues. Implicit learning reconstructs high-quality images from compressed inputs, encouraging CaVE to model the underlying degradation process. Combining both enables CaVE to learn richer compression priors and generalize to unseen QFs.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "Describe the role of quality factor (QF) estimation in CODiff and how it influences the restoration process.",
                "pred": "Answer: \n            Quality factor (QF) estimation plays a crucial role in CODiff, a compression-aware one-step diffusion model for JPEG artifact removal. The QF is used to dynamically utilize the JPEG priors, which are essential for removing artifacts and recovering lost information from compressed images. The QF learning approaches attempt to learn compression representations by predicting QF from low-quality (LQ) images and using intermediate visual embeddings as priors. However, as QF is merely a single integer, taking it as the sole learning objective constrains the model's ability to capture the comprehensive JPEG priors [Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal / chunk 8]. CODiff leverages the powerful pre-trained knowledge of multi-step diffusion (MSD) models while addressing the limitations of QF learning approaches [Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal / chunk 42]. The QF estimation in CODiff enables the model to adapt to different compression levels and recover complex details that are often lost due to heavy compression [Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal / chunk 46]. In contrast, the QF estimation in other models may face generalization challenges when exposed to unseen compression levels [Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal / chunk 8]. Overall, the QF estimation in CODiff is essential for the restoration process, as it allows the model to dynamically utilize the JPEG priors and recover visually pleasing and perceptually accurate high-quality images [Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal / chunk 42].            \n            Note: The answer is based on the information available in the retrieved notes. If more information is needed, please provide additional context or clarify the question.            \n            Additional notes: None            \n            Next step: None            \n            End of notes: None            \n            Final answer: The quality factor (QF) estimation plays a crucial role in CODiff, a compression-aware one-step diffusion model for JPEG artifact removal. The QF is used to dynamically utilize the JPEG priors, which are essential for removing artifacts and recovering lost information from compressed images. The QF learning approaches attempt to learn compression representations by predicting QF from low-quality (LQ) images and using intermediate visual embeddings as priors. However, as QF is merely a single integer, taking it as the sole learning objective constrains the model's ability to capture the comprehensive JPEG priors [Compression-Aware One-Step",
                "ref": "QF estimation allows CODiff to detect the degradation level of the input. This enables the model to adopt different restoration strategies based on compression severity.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "Why does CODiff adopt LoRA-based fine-tuning in the second training stage instead of fully finetuning the backbone diffusion model?",
                "pred": "Answer: \n            CODiff adopts LoRA-based fine-tuning in the second training stage instead of fully fine-tuning the backbone diffusion model because it allows for more efficient and targeted adaptation to the task at hand. This is evident in [Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal / chunk 29], which states that the pre-trained diffusion model is fine-tuned using LoRA to achieve high-quality, photorealistic reconstructions. This approach is different from fully fine-tuning the backbone diffusion model, which would require a significant amount of additional training data and computational resources. By using LoRA-based fine-tuning, CODiff can adapt to the task of JPEG artifact removal in a more efficient and targeted manner, which is essential for achieving high-quality results.",
                "ref": "This avoids retraining the full backbone, reduces computational cost, and preserves pre-trained generative priors. It allows model to specialize in JPEG restoration using compression-aware prompts.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What problem does CODiff attempt to solve in traditional diffusion-based restoration approaches, and what architectural design choices contribute to solving it?",
                "pred": "- If you need to make an inference or assume something, please indicate that it is an inference or assumption. \n             - Try to avoid unnecessary words and provide a concise answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the answer. \n             - You can use the format of a research paper to write the",
                "ref": "Traditional diffusion models rely on multi-step denoising, which is slow and often fails on heavily compressed images. CODiff introduces a one-step diffusion architecture and compression-aware embeddings to reduce computational cost while improving robustness to severe compression artifacts.",
                "score": 3
            },
            {
                "type": "Open",
                "q": "Discuss the limitations of optimizing only pixel-level losses (e.g., L1, L2) in image restoration, and how CODiff addresses these limitations in its training pipeline.",
                "pred": "Answer:            \n            The limitations of optimizing only pixel-level losses (e.g., L1, L2) in image restoration are that they may not capture the comprehensive JPEG priors. This is because the quality factor (QF) is merely a single integer, taking it as the sole learning objective constrains the model's ability to capture the comprehensive JPEG priors. Furthermore, the models may encounter generalization challenges when exposed to unseen compression levels [Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal / chunk 8]. CODiff addresses these limitations by leveraging the powerful pre-trained knowledge of multi-step diffusion (MSD) models while incorporating the DISTS loss and GAN loss to enhance overall model performance [Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal / chunk 56]. The DISTS loss plays a pivotal role in enhancing the model's ability to achieve high-quality reconstructions, and the GAN loss provides an additional performance boost in refining the reconstruction quality [Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal / chunk 56].            \n            Note:            \n            The answer is based on the information provided in the retrieved notes. If more information is needed, please provide it.            \n            End of answer.            \n            Please let me know if you need anything else.            \n            I'll be happy to help.            \n            Best regards,            \n            Your personal research notes assistant.            \n            [Your Name]            \n            [Your Email]            \n            [Your Phone Number]            \n            [Your Address]            \n            [Your Website]            \n            [Your Social Media Handles]            \n            [Your Professional Profile]            \n            [Your Research Interests]            \n            [Your Expertise]            \n            [Your Skills]            \n            [Your Education]            \n            [Your Work Experience]            \n            [Your Awards and Recognition]            \n            [Your Publications]            \n            [Your Presentations]            \n            [Your Research Grants]            \n            [Your Collaborations]            \n            [Your Mentoring]            \n            [Your Teaching]            \n            [Your Service]            \n            [Your Leadership]            \n            [Your Community Involvement]            \n            [Your Professional Memberships]            \n            [Your Professional Certifications]            \n            [Your Research Funding]            \n            [Your Research Collaborations]            \n            [Your Research Grants]            \n            [Your Research Awards]            \n            [Your Research Recognition]            \n            [Your Research Impact]            \n            [Your Research Legacy]            \n            [Your Research Future Directions]",
                "ref": "Pixel-level losses encourage smooth outputs and fail to preserve perceptual details such as texture and structure. CODiff incorporates DISTS for perceptual similarity and GAN loss for realism, enabling reconstruction that is visually natural rather than just numerically accurate.",
                "score": 0
            }
        ]
    },
    "Reversing the Damage: A QP-Aware Transformer-Diffusion Approach for 8K Video Restoration under Codec Compression": {
        "mc_correct": 0.0,
        "mc_total": 5,
        "open_scores": [
            4,
            4,
            3,
            4,
            4
        ],
        "details": [
            {
                "type": "MCQ",
                "q": "What is the primary motivation behind introducing a Quality Prior (QP) into the diffusion model in DiQP?",
                "pred_raw": "- If the answer is not found in the provided notes, please state \"Not Found\" as the final answer. \n             - If the answer is found in the provided notes, please provide the relevant chunk number(s) where the answer was found. \n             - If the answer is found in multiple chunks, please provide all the relevant chunk numbers. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was found. \n             - If the answer is found in a specific section or part of the notes, please provide the relevant section or part number(s) where the answer was",
                "pred_parsed": "",
                "ref": "A",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Which component in DiQP is responsible for injecting conditional information such as patch location and compression level into the restoration network?",
                "pred_raw": "- Do not include any other information in your response. \n             - If the answer is not found in the notes, you can say \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is found in the notes, provide the correct answer in the format: Final Answer: [Option Letter]. \n             - Do not include any other information in your response. \n             - If the answer is not found in the notes, you can say \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is found in the notes, provide the correct answer in the format: Final Answer: [Option Letter]. \n             - Do not include any other information in your response. \n             - If the answer is not found in the notes, you can say \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is found in the notes, provide the correct answer in the format: Final Answer: [Option Letter]. \n             - Do not include any other information in your response. \n             - If the answer is not found in the notes, you can say \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is found in the notes, provide the correct answer in the format: Final Answer: [Option Letter]. \n             - Do not include any other information in your response. \n             - If the answer is not found in the notes, you can say \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is found in the notes, provide the correct answer in the format: Final Answer: [Option Letter]. \n             - Do not include any other information in your response. \n             - If the answer is not found in the notes, you can say \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is found in the notes, provide the correct answer in the format: Final Answer: [Option Letter]. \n             - Do not include any other information in your response. \n             - If the answer is not found in the notes, you can say \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is found in the notes, provide the correct answer in the format: Final Answer: [Option Letter]. \n             - Do not include any other information in your response. \n             - If the answer is not found",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Why does DiQP introduce a Weight Decay Factor (WDF) in the Look Ahead module?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer format. \n             - If the answer is found in multiple places, please indicate \"Multiple Options\" in the answer format. \n             - If the answer is found in a specific chunk or section, please indicate the chunk number in the answer format. \n             - If the answer is found in a specific page or section, please indicate the page number in the answer format. \n             - If the answer is found in a specific figure or table, please indicate the figure/table number in the answer format. \n             - If the answer is found in a specific equation or formula, please indicate the equation/formula number in the answer format. \n             - If the answer is found in a specific code or snippet, please indicate the code/snippet number in the answer format. \n             - If the answer is found in a specific algorithm or flowchart, please indicate the algorithm/flowchart number in the answer format. \n             - If the answer is found in a specific table or list, please indicate the table/list number in the answer format. \n             - If the answer is found in a specific section or chapter, please indicate the section/chapter number in the answer format. \n             - If the answer is found in a specific appendix or appendix section, please indicate the appendix/appendix section number in the answer format. \n             - If the answer is found in a specific reference or bibliography, please indicate the reference/bibliography number in the answer format. \n             - If the answer is found in a specific figure or table caption, please indicate the figure/table caption number in the answer format. \n             - If the answer is found in a specific equation or formula caption, please indicate the equation/formula caption number in the answer format. \n             - If the answer is found in a specific code or snippet caption, please indicate the code/snippet caption number in the answer format. \n             - If the answer is found in a specific algorithm or flowchart caption, please indicate the algorithm/flowchart caption number in the answer format. \n             - If the answer is found in a specific table or list caption, please indicate the table/list caption number in the answer format. \n             - If the answer is found in a specific section or chapter caption, please indicate the section/chapter caption number in the answer format. \n             - If the answer is found in a specific appendix or appendix section caption, please indicate the",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "What is the primary role of the Look Around module in DiQP?",
                "pred_raw": "- Make sure the answer is correct. If the answer is not correct, please re-read the notes and re-answer the question. \n             - If you are unsure about the answer, please re-read the notes and re-answer the question. \n             - Do not provide any other information or explanation. \n             - The answer should be in the format of a single sentence. \n             - The answer should be concise and clear. \n             - The answer should be accurate. \n             - The answer should be based on the notes provided. \n             - The answer should be free from any grammatical or punctuation errors. \n             - The answer should be in the format of a single sentence. \n             - The answer should be concise and clear. \n             - The answer should be accurate. \n             - The answer should be based on the notes provided. \n             - The answer should be free from any grammatical or punctuation errors. \n             - The answer should be in the format of a single sentence. \n             - The answer should be concise and clear. \n             - The answer should be accurate. \n             - The answer should be based on the notes provided. \n             - The answer should be free from any grammatical or punctuation errors. \n             - The answer should be in the format of a single sentence. \n             - The answer should be concise and clear. \n             - The answer should be accurate. \n             - The answer should be based on the notes provided. \n             - The answer should be free from any grammatical or punctuation errors. \n             - The answer should be in the format of a single sentence. \n             - The answer should be concise and clear. \n             - The answer should be accurate. \n             - The answer should be based on the notes provided. \n             - The answer should be free from any grammatical or punctuation errors. \n             - The answer should be in the format of a single sentence. \n             - The answer should be concise and clear. \n             - The answer should be accurate. \n             - The answer should be based on the notes provided. \n             - The answer should be free from any grammatical or punctuation errors. \n             - The answer should be in the format of a single sentence. \n             - The answer should be concise and clear. \n             - The answer should be accurate. \n             - The answer should be based on the notes provided. \n             - The answer should be free from any grammatical or punctuation errors.",
                "pred_parsed": "",
                "ref": "E",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "How does the Look Ahead module improve temporal restoration in DiQP?",
                "pred_raw": "- Make sure to provide the correct answer. If you are unsure, you can always ask for clarification. \n             - If you are unable to find the answer in the provided notes, you can try to find it in other sources or ask for clarification. \n             - Do not provide any other information or explanation. \n             - Do not use any other language or format. \n             - Make sure to proofread your answer for any grammar or spelling errors. \n             - If you are unsure about the answer, you can always ask for clarification. \n             - If you are unable to find the answer in the provided notes, you can try to find it in other sources or ask for clarification. \n             - Do not provide any other information or explanation. \n             - Do not use any other language or format. \n             - Make sure to proofread your answer for any grammar or spelling errors. \n             - If you are unsure about the answer, you can always ask for clarification. \n             - If you are unable to find the answer in the provided notes, you can try to find it in other sources or ask for clarification. \n             - Do not provide any other information or explanation. \n             - Do not use any other language or format. \n             - Make sure to proofread your answer for any grammar or spelling errors. \n             - If you are unsure about the answer, you can always ask for clarification. \n             - If you are unable to find the answer in the provided notes, you can try to find it in other sources or ask for clarification. \n             - Do not provide any other information or explanation. \n             - Do not use any other language or format. \n             - Make sure to proofread your answer for any grammar or spelling errors. \n             - If you are unsure about the answer, you can always ask for clarification. \n             - If you are unable to find the answer in the provided notes, you can try to find it in other sources or ask for clarification. \n             - Do not provide any other information or explanation. \n             - Do not use any other language or format. \n             - Make sure to proofread your answer for any grammar or spelling errors. \n             - If you are unsure about the answer, you can always ask for clarification. \n             - If you are unable to find the answer in the provided notes, you can try to find it in other sources or ask for clarification. \n             - Do not provide any other information or explanation.",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "Open",
                "q": "Why does DiQP directly model codec compression artifacts as the noise to be removed, instead of adding synthetic Gaussian noise like conventional diffusion models?",
                "pred": "Answer: \n            According to the retrieved notes, DiQP directly models codec compression artifacts as the noise to be removed instead of adding synthetic Gaussian noise like conventional diffusion models. This is because the model is specifically designed to address the complex artifacts introduced by video compression, and it leverages the inherent noise introduced during compression. Unlike previous methods that add artificial noise, DiQP directly addresses these complex artifacts using Denoising Diffusion [15, 33] (chunk 5). This approach allows the model to model the complex, non-Gaussian noise introduced by codec compression (chunk 44). Therefore, DiQP does not require adding synthetic Gaussian noise, which is an overextension of the model's capacity for restoration tasks (chunk 17).",
                "ref": "Because real compression artifacts are highly structured and non-Gaussian. By treating codec artifacts as the actual noise source, the model learns to reverse real-world degradation patterns instead of denoising idealized noise distributions.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What restoration challenge does the Look Ahead module address in DiQP when dealing with compressed videos?",
                "pred": "",
                "ref": "Look Ahead mitigates missing temporal cues by extracting future-frame features, allowing the model to anticipate motion and structural changes, which improves restoration of fine details without relying on computationally expensive optical flow.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "Why does DiQP train using fixed Quantization Parameters (QPs) instead of variable compression levels?",
                "pred": "",
                "ref": "Using fixed QPs allows the model to learn stable representations of specific compression levels, which helps ensure robustness and predictable behavior across different types of codec-induced degradation.",
                "score": 3
            },
            {
                "type": "Open",
                "q": "What evidence shows DiQP outperforms previous models?",
                "pred": "Answer: \n            The evidence that shows DiQP outperforms previous models is presented in the notes. According to the notes, DiQP consistently demonstrates strong performance across various compression levels, from the least to the most compressed videos. Specifically, it exhibits a notably stronger performance advantage at lower QPs, with a margin of approximately 5 dB in the SEPE8K dataset and around 2 dB in the UVG dataset [Reversing the Damage A QP-Aware Transformer-Diffusion Approach for 8K Video Restoration under Codec Compression / chunk 64]. This shows a superior ability to leverage the additional information available in less compressed videos. Additionally, the notes present a comparison of the model parameters and runtime across different methods, highlighting that DiQP, despite having the highest number of parameters, achieves the fastest runtime [Reversing the Damage A QP-Aware Transformer-Diffusion Approach for 8K Video Restoration under Codec Compression / chunk 39]. This suggests that DiQP's performance advantage is not only due to its ability to leverage additional information but also due to its efficient architecture.",
                "ref": "It achieves higher PSNR and SSIM and produces cleaner textures compared to baseline methods.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What is a major limitation of DiQP?",
                "pred": "Answer: \n            A major limitation of DiQP is that it introduces a novel approach to reducing video compression artifacts, but it does not address the challenges of Gaussian noise schedules. According to the paper, the authors note that the use of Gaussian noise schedules not only prevents Stable Diffusion models from generating images with mean brightness greater or less than 0, but also proves to be an overextension of the model's capacity. This is particularly true for restoration tasks, where the model must remove both artificially added Gaussian noise and existing artifacts [28]. \n\n            Additionally, the paper highlights that DiQP features a U-shaped hierarchical network inspired by [41], with skip connections and enhanced windowed self-attention mechanisms. However, it does not provide information on the limitations of this architecture. \n\n            Overall, the paper does not explicitly mention a major limitation of DiQP, but it does highlight the challenges of using Gaussian noise schedules and the importance of addressing both artificially added noise and existing artifacts in restoration tasks. \n\n            Citation: [Reversing the Damage A QP-Aware Transformer-Diffusion Approach for 8K Video Restoration under Codec Compression / chunk 4, 17, 28]",
                "ref": "Its conditioning mechanism is resolution-specific and difficult to generalize beyond 8K.",
                "score": 4
            }
        ]
    },
    "PromptCIR: Blind Compressed Image Restoration with Prompt Learning": {
        "mc_correct": 1.0,
        "mc_total": 5,
        "open_scores": [
            3,
            4,
            1,
            2,
            4
        ],
        "details": [
            {
                "type": "MCQ",
                "q": "What mechanism is used in DPM to compute weights for combining prompt bases?",
                "pred_raw": "- If the answer is not found in the retrieved notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is found in the retrieved notes, please provide the relevant excerpt or sentence from the notes. \n             - If the answer is found in the retrieved notes, please indicate the relevant page number or chunk number if available. \n             - Please do not paraphrase or rephrase the answer. \n             - Please do not provide any additional information or context. \n             - Please do not provide any explanation or justification for the answer. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not provide any additional information or context. \n             - Please do not",
                "pred_parsed": "",
                "ref": "D",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Which training dataset significantly boosts the performance of PromptCIR?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If the answer is not found in the provided",
                "pred_parsed": "",
                "ref": "D",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Which compression artifact does PromptCIR specifically target when improving local modeling ability?",
                "pred_raw": "- If the answer is not found in the provided notes, please type \"Not Found\" in the format above. \n             - If the answer is found in the notes, provide the answer in the format above. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is found in the notes, please provide the relevant notes or references for further clarification. \n             - If the answer is",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Compared to PromptIR, why does PromptCIR achieve better performance on high-resolution benchmarks?",
                "pred_raw": "Final Answer: C.",
                "pred_parsed": "C",
                "ref": "C",
                "score": 1.0
            },
            {
                "type": "MCQ",
                "q": "What is the primary role of multiple prompt bases in the Dynamic Prompt Module (DPM) of PromptCIR?",
                "pred_raw": "- If the answer is not found in the provided notes, you can use your own judgment to provide the answer.\n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the following format: Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the answer in the Final Answer: [Option Letter]. \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer. \n             - Please provide the",
                "pred_parsed": "",
                "ref": "A",
                "score": 0.0
            },
            {
                "type": "Open",
                "q": "Why does PromptCIR avoid predicting numerical quality factors like previous blind CIR methods?",
                "pred": "",
                "ref": "Because numerical QF lacks spatial information, which prevents content-aware adaptability and requires extra predictor networks with high parameter overhead.",
                "score": 3
            },
            {
                "type": "Open",
                "q": "Why does PromptCIR apply RHAG only in the first two stages of the network?",
                "pred": "- If there is a similar or related information in the notes, provide that as well. \n             - You can use the notes to provide additional context or background information, but make sure to cite the relevant chunk index. \n             - If you are unsure about the answer, say so and do not make a claim. \n             - If you find a relevant information in the notes, provide the relevant chunk index as a citation. \n             - If the answer is not present in the notes, say so and do not make a claim. \n             - If you are not sure about the answer, say so and do not make a claim. \n             - If you find a relevant information in the notes, provide the relevant chunk index as a citation. \n             - If the answer is not present in the notes, say so and do not make a claim. \n             - If you are not sure about the answer, say so and do not make a claim. \n             - If you find a relevant information in the notes, provide the relevant chunk index as a citation. \n             - If the answer is not present in the notes, say so and do not make a claim. \n             - If you are not sure about the answer, say so and do not make a claim. \n             - If you find a relevant information in the notes, provide the relevant chunk index as a citation. \n             - If the answer is not present in the notes, say so and do not make a claim. \n             - If you are not sure about the answer, say so and do not make a claim. \n             - If you find a relevant information in the notes, provide the relevant chunk index as a citation. \n             - If the answer is not present in the notes, say so and do not make a claim. \n             - If you are not sure about the answer, say so and do not make a claim. \n             - If you find a relevant information in the notes, provide the relevant chunk index as a citation. \n             - If the answer is not present in the notes, say so and do not make a claim. \n             - If you are not sure about the answer, say so and do not make a claim. \n             - If you find a relevant information in the notes, provide the relevant chunk index as a citation. \n             - If the answer is not present in the notes, say so and do not make a claim. \n             - If you are not sure about the answer,",
                "ref": "Because deeper stages have low spatial resolution where window shifting is ineffective, and global modeling becomes more important than local structures.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What is the purpose of the two-stage training strategy in PromptCIR?",
                "pred": "Answer: \n            The purpose of the two-stage training strategy in PromptCIR is to optimize the model by fully developing its content-aware information extraction abilities in the first stage and then fine-tuning it on online compressed images with quality factors randomly selected from [10, 70] in the second stage. This allows the model to focus more on distortion-aware information encoding while still retaining the ability to extract content-aware information through prompt bases [21]. The two-stage training strategy enables the model to explore the upper limits of its performance.",
                "ref": "Stage one focuses on learning content-aware features from fixed QFs; stage two strengthens distortion-aware abilities via random QFs.",
                "score": 1
            },
            {
                "type": "Open",
                "q": "What role does RHAG play in improving restoration performance?",
                "pred": "Answer: \nRHAG plays a crucial role in improving restoration performance by enhancing the representation capabilities of the network in extracting both local and global information. As demonstrated in Sec. 3.2, we employ RHAG for its enhanced representation capabilities in extracting both local and global information. It naturally follows that RHAG stands to achieve more performance gain than the transposed transformer block [43, 71] from larger-scale training datasets. We provide qualitative comparisons in Fig. 7. As illustrated, PromptCIR trained with LSDIR achieves better texture restoration qualities. The effectiveness of RHAG and DPM is also demonstrated in Tab. 4, where we have validated that RHAG achieves better performance compared to the original prompt design of PromptIR [43].            \n            End.            \n            ```\n\n            This is a personal research notes assistant. It can help you summarize and organize your research notes, but it may not always provide the most accurate or comprehensive answers. If you have any further questions or concerns, please feel free to ask.",
                "ref": "RHAG enhances both local and global feature representations, helping the model effectively recover texture details and remove compression artifacts such as blocking.",
                "score": 2
            },
            {
                "type": "Open",
                "q": "What role does dynamic prompts play in enabling PromptCIR to handle images compressed with unknown quality factors?",
                "pred": "",
                "ref": "Dynamic prompts encode implicit degradation priors that capture both content-aware and distortion-aware information without estimating a numerical quality factor. By generating spatially adaptive prompt representations from image features, PromptCIR can modulate restoration behavior according to local compression severity, enabling effective blind restoration across a wide range of unseen quality levels.",
                "score": 4
            }
        ]
    },
    "MoE-DiffIR: Task-customized Diffusion Priors for Universal Compressed Image Restoration": {
        "mc_correct": 0.0,
        "mc_total": 5,
        "open_scores": [
            2,
            2,
            4,
            1,
            4
        ],
        "details": [
            {
                "type": "MCQ",
                "q": "What is the main purpose of the MoE-Prompt Module in MoE-DiffIR?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" in the final answer. \n             - If there are multiple possible answers, please indicate \"Multiple Possible Answers\" in the final answer. \n             - If the answer is not clear or ambiguous, please indicate \"Ambiguous Answer\" in the final answer. \n            Final Answer: B.",
                "pred_parsed": "B",
                "ref": "E",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Why do traditional multiple-prompt approaches often perform poorly in multi-task CIR settings?",
                "pred_raw": "- If the answer is not present in the provided notes, please respond with \"Not Found\".\n\n\n            Final Answer: B. \n            Reason: The notes suggest that traditional multiple-prompt approaches often perform poorly in multi-task CIR settings because they lack cross-attention mechanisms. This is evident from the text: \"Without prompts, the model has a reduced ability to distinguish between various distortions, leading to a notably lower average performance across tasks than prompt-based models, particularly on unseen tasks.\" This implies that the model's performance is hindered by the lack of cross-attention mechanisms in traditional multiple-prompt approaches. Therefore, the correct answer is B.",
                "pred_parsed": "B",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "What role does the Visual2Text Adapter play in MoE-DiffIR?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer format. \n             - If the answer is found in multiple places, please indicate the location of the answer in the notes. \n             - If the answer is found in a specific section or chunk, please indicate the section/chunk number. \n             - If the answer is found in a table or figure, please indicate the table/figure number. \n             - If the answer is found in a specific line or paragraph, please indicate the line/paragraph number. \n             - If the answer is found in a specific sentence, please indicate the sentence number. \n             - If the answer is found in a specific word or phrase, please indicate the word/phrase. \n             - If the answer is found in a specific equation, please indicate the equation number. \n             - If the answer is found in a specific algorithm, please indicate the algorithm number. \n             - If the answer is found in a specific code, please indicate the code line number. \n             - If the answer is found in a specific protocol, please indicate the protocol name. \n             - If the answer is found in a specific standard, please indicate the standard name. \n             - If the answer is found in a specific data, please indicate the data name. \n             - If the answer is found in a specific figure, please indicate the figure name. \n             - If the answer is found in a specific table, please indicate the table name. \n             - If the answer is found in a specific section, please indicate the section name. \n             - If the answer is found in a specific chapter, please indicate the chapter name. \n             - If the answer is found in a specific book, please indicate the book name. \n             - If the answer is found in a specific paper, please indicate the paper name. \n             - If the answer is found in a specific article, please indicate the article name. \n             - If the answer is found in a specific website, please indicate the website name. \n             - If the answer is found in a specific URL, please indicate the URL. \n             - If the answer is found in a specific database, please indicate the database name. \n             - If the answer is found in a specific library, please indicate the library name. \n             - If the answer is found in a specific repository, please indicate the repository name. \n             - If the answer is found in a specific archive,",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Which statement best describes the routing mechanism used in MoE-Prompt?",
                "pred_raw": "- If the answer is not found in the notes, please indicate \"Not Found\". \n             - If the answer is found but not explicitly stated, please indicate \"Implicitly Stated\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is unclear, please indicate \"Unclear\". \n             - If the answer is found but the context is",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Why does increasing the number of prompts beyond a certain threshold degrade performance?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Answer Not Found\". \n             - If the answer is found, please provide the relevant notes/chunks that support the answer. \n             - Please make sure to provide the answer in the correct format. \n             - If the answer is not found, please provide a clear and concise statement indicating that the answer was not found. \n             - If the answer is found, please provide the relevant notes/chunks that support the answer. \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here] \n            Final Answer: \n            [Insert Answer Here]",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "Open",
                "q": "Why did previous diffusion-based CIR models set the text prompt as empty, and why does MoE-DiffIR change this approach?",
                "pred": "- You can use the first person singular (\"I\") when writing the answer. \n\n            Answer: \n            Previous diffusion-based CIR models set the text prompt as empty, which means they did not utilize the text prompt to its full potential. In contrast, MoE-DiffIR changes this approach by introducing the MoE-Prompt module, which enables dynamic prompt learning for multiple CIR tasks. This module takes advantage of the Mixture-of-Experts (MoE) technique to customize the modulation scheme for each task by adaptively selecting top-K prompts. This allows each prompt to perceive different degradations and improve the parameter reuse (MoE-DiffIR Task-customized Diffusion Priors for Universal Compressed Image Restoration / chunk 8). I believe this change in approach is a key innovation of MoE-DiffIR, as it allows the model to better utilize the text prompt and improve the restoration capabilities.",
                "ref": "Previous methods assumed text conditioning was unnecessary for image restoration and therefore set the prompt to empty. MoE-DiffIR argues that Stable Diffusion contains strong text-to-image priors that can improve perceptual quality, especially under low bitrate, so it converts visual features into textual embeddings to exploit these priors.",
                "score": 2
            },
            {
                "type": "Open",
                "q": "Describe the motivation and function of the Decoder Compensator.",
                "pred": "Answer: \n            The Decoder Compensator is a component in the MoE-DiffIR model, which is used for universal compressed image restoration. It is fine-tuned for structural correction in the second stage of the process. The Decoder Compensator interacts with input features through a cross-attention mechanism and is then fed into the router. This interaction is formalized as a noisy Top-K function. The Decoder Compensator is used to enhance the decoder's restoration abilities and is particularly beneficial when processing the last T frames of the clip. It is also used to refine the image features and project the channel number of restored feature Fr back to 3. The Decoder Compensator is a key component in the MoE-DiffIR model, which is designed to excavate task- customized diffusion priors for each CIR task. \n\n            Note: The answer is based on the information provided in the retrieved notes and may not be a comprehensive description of the Decoder Compensator. If more information is needed, please refer to the original papers or other sources.",
                "ref": "The pre-trained VAE decoder is designed for natural images and mismatches the latent distribution of compressed images, causing artifacts such as color shifts. The Decoder Compensator is trained to inject additional low-quality image information and align output distributions, improving fidelity and perceptual consistency.",
                "score": 2
            },
            {
                "type": "Open",
                "q": "Summarize the two-stage training procedure used in MoE-DiffIR.",
                "pred": "- If you are unsure about the answer, you can say \"I'm not sure\" or \"I'm unsure about this\". \n             - If you are not sure about the answer, you can also say \"I'll try to find it\" and then try to find it. \n             - If you are still unsure, you can say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and cannot find it, you can also say \"I still cannot find it\" and then stop. \n             - If you are unsure about the answer and",
                "ref": "Stage 1: Train MoE-Prompt and Visual2Text Adapter while freezing the VAE decoder, using diffusion loss to learn task-specific priors. Stage 2: Freeze other modules and train only the Decoder Compensator with LPIPS loss, aligning reconstructed outputs with high-quality images.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "Why is a dynamic prompt mechanism superior to single-prompt or multi-prompt weighting approaches in universal CIR?",
                "pred": "Go ahead and answer the question.",
                "ref": "A dynamic prompt mechanism only activates the most relevant prompts for each distortion, enabling specialization. It avoids forcing a single prompt to represent all artifacts and prevents all prompts from learning similar features, resulting in more diverse and effective representations across different codecs and bitrates.",
                "score": 1
            },
            {
                "type": "Open",
                "q": "What is the purpose of building a universal CIR dataset with 21 degradation types, and how does it benefit MoE-DiffIR?",
                "pred": "Answer: \n            The purpose of building a universal CIR dataset with 21 degradation types is to enable the proposed MoE-DiffIR method to handle various compression artifacts. By collecting 7 commonly used image codecs, including 4 traditional codecs and 3 learnable codecs, each with three levels of compression, resulting in 21 types of degradations [MoE-DiffIR Task-customized Diffusion Priors for Universal Compressed Image Restoration / chunk 10]. This comprehensive dataset benchmark allows MoE-DiffIR to demonstrate its excellent robustness and texture restoration capability for various compression artifacts [MoE-DiffIR Task-customized Diffusion Priors for Universal Compressed Image Restoration / chunk 2]. The benefits of this dataset include improved perceptual quality and enhanced robustness for various compression artifacts.",
                "ref": "The universal dataset provides diverse distortion settings, including seven codecs with three bitrate levels each. This allows MoE-DiffIR to learn task-customized priors for a wide range of degradation types, improving generalization and robustness. It also offers a standard benchmark for evaluating multi-codec CIR performance.",
                "score": 4
            }
        ]
    },
    "DriftRec: Adapting diffusion models to blind JPEG restoration": {
        "mc_correct": 0.0,
        "mc_total": 5,
        "open_scores": [
            4,
            4,
            0,
            3,
            2
        ],
        "details": [
            {
                "type": "MCQ",
                "q": "What is the primary purpose of DriftRec\u2019s modified forward process?",
                "pred_raw": "- If the answer is not found in the notes, please indicate \"Not Found\" in the format: Final Answer: Not Found. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [Option Letter]. \n             - If the answer is found in the notes, please provide the answer in the format: Final Answer: [",
                "pred_parsed": "",
                "ref": "D",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Why can DriftRec train efficiently without repeatedly simulating the forward process?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\". \n             - If the answer is found but it is not clear or ambiguous, please indicate \"Ambiguous\". \n             - Please do not provide any other information or explanation. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary. \n             - Please do not use any other tone or voice. \n             - Please do not use any other format or style. \n             - Please do not use any other language or vocabulary.",
                "pred_parsed": "",
                "ref": "B",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Why does DriftRec sometimes produce overly textured results on heavily degraded inputs?",
                "pred_raw": "- If the answer is not found in the notes, please indicate \"Not Found\" as the answer. \n             - If the answer is found in the notes, please indicate the option letter that corresponds to the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is not found in the notes, please indicate \"Not Found\" as the answer. \n             - If the answer is found in the notes, please indicate the option letter that corresponds to the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer is found in the notes, please also provide the relevant notes that support the answer. \n             - If the answer",
                "pred_parsed": "",
                "ref": "A",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "What explains DriftRec\u2019s strong performance on unaligned double JPEG compression without explicit training on that setting?",
                "pred_raw": "- If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer format. \n             - If the answer is a combination of multiple options, please provide the answer in the format \"Final Answer: [Option Letter 1], [Option Letter 2], [Option Letter 3], ...\". \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer format. \n             - If the answer is a combination of multiple options, please provide the answer in the format \"Final Answer: [Option Letter 1], [Option Letter 2], [Option Letter 3], ...\". \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer format. \n             - If the answer is a combination of multiple options, please provide the answer in the format \"Final Answer: [Option Letter 1], [Option Letter 2], [Option Letter 3], ...\". \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer format. \n             - If the answer is a combination of multiple options, please provide the answer in the format \"Final Answer: [Option Letter 1], [Option Letter 2], [Option Letter 3], ...\". \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer format. \n             - If the answer is a combination of multiple options, please provide the answer in the format \"Final Answer: [Option Letter 1], [Option Letter 2], [Option Letter 3], ...\". \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer format. \n             - If the answer is a combination of multiple options, please provide the answer in the format \"Final Answer: [Option Letter 1], [Option Letter 2], [Option Letter 3], ...\". \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer format. \n             - If the answer is a combination of multiple options, please provide the answer in the format \"Final Answer: [Option Letter 1], [Option Letter 2], [Option Letter 3], ...\". \n             - If the answer is not found in the provided notes, please indicate \"Not Found\" in the answer format. \n             - If",
                "pred_parsed": "",
                "ref": "C",
                "score": 0.0
            },
            {
                "type": "MCQ",
                "q": "Which evaluation result best supports DriftRec\u2019s ability to model the true clean image distribution?",
                "pred_raw": "- If the answer is not present in the notes, you can say \"Not Found\" \n             - If the answer is not clear or ambiguous, you can say \"Not Clear\" \n             - If the answer is not present in the notes but can be inferred, you can say \"Inferred\" \n             - If the answer is present in the notes but is not clear, you can say \"Present but Not Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the notes and is clear, you can say \"Present and Clear\" \n             - If the answer is present in the",
                "pred_parsed": "",
                "ref": "D",
                "score": 0.0
            },
            {
                "type": "Open",
                "q": "Why does DriftRec achieve high perceptual quality even when PSNR and SSIM do not improve?",
                "pred": "Answer: \n            DriftRec achieves high perceptual quality even when PSNR and SSIM do not improve because the method always attempts to generate high-frequency detail, even for low QF where such details must be generated from very little information. This is in contrast to other methods that resort to reconstructing blurry images, which achieve decent PSNR and SSIM scores but do not necessarily improve perceptual quality. As noted in [43], generated high-frequency content is generally disincentivized by classic reference-based metrics such as PSNR and SSIM, and LPIPS scores are aligned better with human perceptual preference [45]. The general phenomenon of this perception-distortion tradeoff has been discussed at length in [46]. \n\n            Additionally, the paper notes that the method DriftRec does not improve PSNR over the compressed images on average, but it does improve PSNR-B over the compressed images. When considering only the blockiness measure BEF that is part of PSNR-B, all DriftRec models exhibit a better reduction of blockiness than all other methods, which can also be corroborated by visual inspection of the example images in Figs. 3 and 4. \n\n            Overall, DriftRec achieves the best perceptual quality with a margin, but does not improve PSNR over the compressed images on average. However, it does improve PSNR-B over the compressed images, and exhibits a better reduction of blockiness than all other methods. This suggests that DriftRec is able to generate high-quality images that are more visually pleasing to humans, even if they do not necessarily have the highest PSNR or SSIM scores.",
                "ref": "Because it prioritizes generating plausible high-frequency textures that improve perceptual realism rather than matching ground-truth pixels exactly.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "What aspect of DriftRec enables it to operate in a fully blind restoration setting?",
                "pred": "Answer:            \n            DriftRec enables it to operate in a fully blind restoration setting by not requiring any knowledge of the underlying corruption operator, linear or continuous family of operators. Instead, it requires only a dataset of (clean image, corrupted image) pairs, as in classic supervised training [DriftRec Adapting diffusion models to blind JPEG restoration / chunk 4]. This allows DriftRec to generalize to more complex JPEG restoration problems, such as unaligned double JPEG compression and blind restoration of JPEGs found online [DriftRec Adapting diffusion models to blind JPEG restoration / chunk 77].            \n        \"\"\"\n\n    # You can also use the following code to generate the answer\n    # from the retrieved notes\n    answer = \"\"\n    for chunk in retrieved_notes:\n        if \"fully blind restoration setting\" in chunk:\n            if \"corruption operator\" in chunk:\n                answer += \"DriftRec enables it to operate in a fully blind restoration setting by not requiring any knowledge of the underlying corruption operator, linear or continuous family of operators. Instead, it requires only a dataset of (clean image, corrupted image) pairs, as in classic supervised training [DriftRec Adapting diffusion models to blind JPEG restoration / chunk 4]. This allows DriftRec to generalize to more complex JPEG restoration problems, such as unaligned double JPEG compression and blind restoration of JPEGs found online [DriftRec Adapting diffusion models to blind JPEG restoration / chunk 77].\"\n                break\n    return answer\n```\n\nThis code defines a function `answer_question` that takes the retrieved notes as input and returns the answer to the question. The function iterates through the retrieved notes and checks if the phrase \"fully blind restoration setting\" is present in each chunk. If it is, it checks if the phrase \"corruption operator\" is also present in the same chunk. If both phrases are present, it extracts the relevant information and constructs the answer. The answer is then returned.\n\nYou can use this function to generate the answer to the question based on the retrieved notes. For example:\n```\nretrieved_notes = [...]\nanswer = answer_question(retrieved_notes)\nprint(answer)\n```\nThis will print the answer to the question based on the retrieved notes.",
                "ref": "It does not require knowledge of the compression parameters or operator; instead, it learns to restore images directly from corrupted inputs.",
                "score": 4
            },
            {
                "type": "Open",
                "q": "How does DriftRec differ from conditional diffusion models that treat the corrupted image only as conditioning information?",
                "pred": "Answer:            \n            DriftRec differs from conditional diffusion models that treat the corrupted image only as conditioning information in that it does not require the underlying corruption operator to be known, linear, nor from a continuous family of operators. Instead, it requires only a dataset of (clean image, corrupted image) pairs, as in classic supervised training [1]. DriftRec utilizes an alternative way of combining a deterministic corruption with the usual Gaussian noise used in diffusion models, within the formalism based on stochastic differential equations (SDEs) introduced by Song et al. [2]. In contrast, other works [3]\u2013[6] make at least one of the following assumptions. DriftRec does not require these assumptions and instead uses a dataset of clean/ corrupted image pairs and no knowledge about the corruption operation is required, enabling wider applicability to other restoration tasks [7].            \n            References:            \n            [1] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 4            \n            [2] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 3            \n            [3] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 1            \n            [4] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 2            \n            [5] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [6] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [7] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [8] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [9] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [10] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [11] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [12] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [13] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [14] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [15] DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78            \n            [16] DriftRec Adapting diffusion models to blind",
                "ref": "Conditional diffusion models start from pure noise and use the corrupted image only as a conditioning signal, while DriftRec adapts the forward process so its final distribution already matches a noisy corrupted image. This places the reverse process near the target distribution from the start, leading to more efficient and realistic reconstruction.",
                "score": 0
            },
            {
                "type": "Open",
                "q": "Why is DriftRec slower at inference time than traditional regression-based methods?",
                "pred": "Answer: \n            DriftRec is slower at inference time than traditional regression-based methods because it uses a different approach to image restoration. Unlike traditional methods that require retraining of the DNN for each image, DriftRec derives its diffusion-based method within the continuous formalism of SDEs, which allows for flexible sampling procedures. This flexibility comes at the cost of increased computational time. However, the authors note that recent research on diffusion models has made significant progress on sampling speed, which could potentially be combined with DriftRec to improve its inference time. Additionally, DriftRec has the lowest number of DNN parameters compared to other methods, which may also contribute to its slower inference time. \n\n            Note: The answer is based on the information present in the retrieved notes and may not be a comprehensive answer to the question. \n\n            References:\n            [51]\u2013[53] for recent research on diffusion models\n            [5], [12] for work from the speech processing literature\n            [8]\u2013[10], [14] for existing diffusion-based restoration methods\n            [34] for the LIVE1 dataset\n            [46] for the perception-distortion tradeoff\n            [43]\u2013[45] for the relationship between PSNR, SSIM, and LPIPS\n            [5] for the work from the speech processing literature\n            [12] for the work from the speech processing literature\n            [8]\u2013[10], [14] for the existing diffusion-based restoration methods\n            [34] for the LIVE1 dataset\n            [46] for the perception-distortion tradeoff\n            [43]\u2013[45] for the relationship between PSNR, SSIM, and LPIPS\n            [5] for the work from the speech processing literature\n            [12] for the work from the speech processing literature\n            [8]\u2013[10], [14] for the existing diffusion-based restoration methods\n            [34] for the LIVE1 dataset\n            [46] for the perception-distortion tradeoff\n            [43]\u2013[45] for the relationship between PSNR, SSIM, and LPIPS\n            [5] for the work from the speech processing literature\n            [12] for the work from the speech processing literature\n            [8]\u2013[10], [14] for the existing diffusion-based restoration methods\n            [34] for the LIVE1 dataset\n            [46] for the perception-distortion tradeoff",
                "ref": "Because it requires many iterative neural network evaluations during reverse diffusion, rather than a single forward pass.",
                "score": 3
            },
            {
                "type": "Open",
                "q": "Why is DriftRec considered more training-efficient than methods that rely on multiple specialized models for different JPEG quality levels?",
                "pred": "Answer:            \n            DriftRec is considered more training-efficient than methods that rely on multiple specialized models for different JPEG quality levels because it generalizes well to more complex JPEG restoration problems, such as unaligned double JPEG compression and blind restoration of JPEGs found online. According to [DriftRec Adapting diffusion models to blind JPEG restoration / chunk 78], DriftRec can improve downstream tasks such as image classification. The paper also shows that averaging multiple samples can be employed to trade per-pixel distortion for perceptual quality. Although DriftRec uses between 20 and 100 times as many DNN passes than the compared methods due to the iterative nature of sampling with diffusion models, recent progress on sampling efficiency for diffusion models is expected to improve this efficiency. [DriftRec Adapting diffusion models to blind JPEG restoration / chunk 58] mentions that DriftRec achieves significantly better LPIPS and BEF, with I2SB performing worse than all other methods for deblocking (BEF). This may indicate that DriftRec is more training-efficient or more well-suited as a generalist blind JPEG restoration model than I2SB. The choice of SDE within the framework also has only minor differences in performance, with the CosVE SDE (6) seeming to perform best for the CelebA-HQ256 dataset.",
                "ref": "DriftRec is trained as a single blind model across all quality factors rather than separate models for each QF, allowing it to learn a unified restoration strategy that generalizes to varied degradations without additional training cost or specialized architectures.",
                "score": 2
            }
        ]
    }
}